{
  "version": "1.0.0",
  "generated_at": "2025-10-23T06:07:41.629868+00:00",
  "total_launchables": 163,
  "launchables": [
    {
      "id": "advanced-llama3-1-3b-grpo-lora/Advanced_Llama3_1_(3B)_GRPO_LoRA",
      "name": "Advanced_Llama3_1_(3B)_GRPO_LoRA",
      "description": "Fine-tune Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-23T06:07:39.445535+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "huggingface course-advanced-llama3-1-3b-grpo-lora/HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA",
      "name": "Advanced_Llama3_1_(3B)_GRPO_LoRA",
      "description": "Fine-tune Huggingface Course Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "huggingface course-advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-23T06:07:39.759237+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "huggingface course-advanced-llama3-2-3b-grpo-lora/HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA",
      "name": "Advanced_Llama3_2_(3B)_GRPO_LoRA",
      "description": "Fine-tune Huggingface Course Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "huggingface course-advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-23T06:07:40.500005+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "advanced-llama3-2-3b-grpo-lora/Advanced_Llama3_2_(3B)_GRPO_LoRA",
      "name": "Advanced_Llama3_2_(3B)_GRPO_LoRA",
      "description": "Fine-tune Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-23T06:07:40.174977+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "codeforces-cot-finetune-for-reasoning-on-codeforces/CodeForces-cot-Finetune_for_Reasoning_on_CodeForces",
      "name": "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces",
      "description": "Fine-tune Codeforces Cot Finetune For Reasoning On Codeforces with Unsloth on NVIDIA GPUs",
      "notebook": "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
      "path": "codeforces-cot-finetune-for-reasoning-on-codeforces",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
        "last_synced": "2025-10-23T06:07:40.713139+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb"
      ]
    },
    {
      "id": "codegemma-7b/CodeGemma_(7B)-Conversational",
      "name": "CodeGemma_(7B)-Conversational",
      "description": "Fine-tune Codegemma (7B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "CodeGemma_(7B)-Conversational.ipynb",
      "path": "codegemma-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/CodeGemma_(7B)-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:41.191593+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "CodeGemma_(7B)-Conversational.ipynb"
      ]
    },
    {
      "id": "huggingface course-deepseek-r1-0528-qwen3-8b/HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO",
      "name": "DeepSeek_R1_0528_Qwen3_(8B)_GRPO",
      "description": "Fine-tune Huggingface Course Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "huggingface course-deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:40.791685+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb"
      ]
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b/DeepSeek_R1_0528_Qwen3_(8B)_GRPO",
      "name": "DeepSeek_R1_0528_Qwen3_(8B)_GRPO",
      "description": "Fine-tune Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:40.374485+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb"
      ]
    },
    {
      "id": "falcon-h1/Falcon_H1-Alpaca",
      "name": "Falcon_H1-Alpaca",
      "description": "Fine-tune Falcon H1 Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Falcon_H1-Alpaca.ipynb",
      "path": "falcon-h1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Falcon_H1-Alpaca.ipynb",
        "last_synced": "2025-10-23T06:07:40.041108+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Falcon_H1-Alpaca.ipynb"
      ]
    },
    {
      "id": "falcon-h1-0/Falcon_H1_(0.5B)-Alpaca",
      "name": "Falcon_H1_(0.5B)-Alpaca",
      "description": "Fine-tune Falcon H1 (0 with Unsloth on NVIDIA GPUs",
      "notebook": "Falcon_H1_(0.5B)-Alpaca.ipynb",
      "path": "falcon-h1-0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Falcon_H1_(0.ipynb",
        "last_synced": "2025-10-23T06:07:40.674416+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Falcon_H1_(0.5B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "gpt-oss-bnb-20b/GPT_OSS_BNB_(20B)-Inference",
      "name": "GPT_OSS_BNB_(20B)-Inference",
      "description": "Fine-tune Gpt Oss Bnb (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "GPT_OSS_BNB_(20B)-Inference.ipynb",
      "path": "gpt-oss-bnb-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/GPT_OSS_BNB_(20B)-Inference.ipynb",
        "last_synced": "2025-10-23T06:07:41.207251+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "GPT_OSS_BNB_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "gpt-oss-mxfp4-20b/GPT_OSS_MXFP4_(20B)-Inference",
      "name": "GPT_OSS_MXFP4_(20B)-Inference",
      "description": "Fine-tune Gpt Oss Mxfp4 (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "GPT_OSS_MXFP4_(20B)-Inference.ipynb",
      "path": "gpt-oss-mxfp4-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "last_synced": "2025-10-23T06:07:40.412993+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "GPT_OSS_MXFP4_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "gemma2-2b/Gemma2_(2B)-Alpaca",
      "name": "Gemma2_(2B)-Alpaca",
      "description": "Fine-tune Gemma2 (2B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma2_(2B)-Alpaca.ipynb",
      "path": "gemma2-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma2_(2B)-Alpaca.ipynb",
        "last_synced": "2025-10-23T06:07:40.254936+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma2_(2B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "gemma2-9b/Gemma2_(9B)-Alpaca",
      "name": "Gemma2_(9B)-Alpaca",
      "description": "Fine-tune Gemma2 (9B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma2_(9B)-Alpaca.ipynb",
      "path": "gemma2-9b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma2_(9B)-Alpaca.ipynb",
        "last_synced": "2025-10-23T06:07:40.113766+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma2_(9B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "gemma3n-2b/Gemma3N_(2B)-Inference",
      "name": "Gemma3N_(2B)-Inference",
      "description": "Fine-tune Gemma3N (2B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(2B)-Inference.ipynb",
      "path": "gemma3n-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(2B)-Inference.ipynb",
        "last_synced": "2025-10-23T06:07:40.150445+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(2B)-Inference.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b-audio/Gemma3N_(4B)-Audio",
      "name": "Gemma3N_(4B)-Audio",
      "description": "Fine-tune Gemma3N (4B) Audio with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Audio.ipynb",
      "path": "gemma3n-4b-audio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Audio.ipynb",
        "last_synced": "2025-10-23T06:07:40.602293+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Audio.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b/Gemma3N_(4B)-Conversational",
      "name": "Gemma3N_(4B)-Conversational",
      "description": "Fine-tune Gemma3N (4B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Conversational.ipynb",
      "path": "gemma3n-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:41.368601+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Conversational.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b-vision/Gemma3N_(4B)-Vision",
      "name": "Gemma3N_(4B)-Vision",
      "description": "Fine-tune Gemma3N (4B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Vision.ipynb",
      "path": "gemma3n-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Vision.ipynb",
        "last_synced": "2025-10-23T06:07:40.581604+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Vision.ipynb"
      ]
    },
    {
      "id": "huggingface course-gemma3-1b/HuggingFace Course-Gemma3_(1B)-GRPO",
      "name": "Gemma3_(1B)-GRPO",
      "description": "Fine-tune Huggingface Course Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Gemma3_(1B)-GRPO.ipynb",
      "path": "huggingface course-gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:40.733526+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gemma3-1b/Gemma3_(1B)-GRPO",
      "name": "Gemma3_(1B)-GRPO",
      "description": "Fine-tune Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(1B)-GRPO.ipynb",
      "path": "gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:41.037874+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gemma3-270m/Gemma3_(270M)",
      "name": "Gemma3_(270M)",
      "description": "Fine-tune Gemma3 (270M) with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(270M).ipynb",
      "path": "gemma3-270m",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(270M).ipynb",
        "last_synced": "2025-10-23T06:07:41.390847+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(270M).ipynb"
      ]
    },
    {
      "id": "gemma3-27b/Gemma3_(27B)_A100-Conversational",
      "name": "Gemma3_(27B)_A100-Conversational",
      "description": "Fine-tune Gemma3 (27B) A100 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(27B)_A100-Conversational.ipynb",
      "path": "gemma3-27b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(27B)_A100-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:40.620549+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(27B)_A100-Conversational.ipynb"
      ]
    },
    {
      "id": "gemma3-4b/Gemma3_(4B)",
      "name": "Gemma3_(4B)",
      "description": "Fine-tune Gemma3 (4B) with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B).ipynb",
      "path": "gemma3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B).ipynb",
        "last_synced": "2025-10-23T06:07:40.093576+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(4B).ipynb"
      ]
    },
    {
      "id": "gemma3-4b-vision/Gemma3_(4B)-Vision",
      "name": "Gemma3_(4B)-Vision",
      "description": "Fine-tune Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B)-Vision.ipynb",
      "path": "gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:41.083869+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(4B)-Vision.ipynb"
      ]
    },
    {
      "id": "gemma3-4b-vision/Gemma3_(4B)-Vision-GRPO",
      "name": "Gemma3_(4B)-Vision-GRPO",
      "description": "Fine-tune Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B)-Vision-GRPO.ipynb",
      "path": "gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:41.083869+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(4B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-gemma3-4b-vision/HuggingFace Course-Gemma3_(4B)-Vision-GRPO",
      "name": "Gemma3_(4B)-Vision-GRPO",
      "description": "Fine-tune Huggingface Course Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
      "path": "huggingface course-gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:39.616559+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "granite4/Granite4.0",
      "name": "Granite4.0",
      "description": "Fine-tune Granite4 with Unsloth on NVIDIA GPUs",
      "notebook": "Granite4.0.ipynb",
      "path": "granite4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Granite4.ipynb",
        "last_synced": "2025-10-23T06:07:40.953208+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Granite4.0.ipynb"
      ]
    },
    {
      "id": "liquid-lfm2/Liquid_LFM2-Conversational",
      "name": "Liquid_LFM2-Conversational",
      "description": "Fine-tune Liquid Lfm2 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Liquid_LFM2-Conversational.ipynb",
      "path": "liquid-lfm2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Liquid_LFM2-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:41.226202+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Liquid_LFM2-Conversational.ipynb"
      ]
    },
    {
      "id": "liquid-lfm2-1/Liquid_LFM2_(1.2B)-Conversational",
      "name": "Liquid_LFM2_(1.2B)-Conversational",
      "description": "Fine-tune Liquid Lfm2 (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Liquid_LFM2_(1.2B)-Conversational.ipynb",
      "path": "liquid-lfm2-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Liquid_LFM2_(1.ipynb",
        "last_synced": "2025-10-23T06:07:39.593241+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Liquid_LFM2_(1.2B)-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.1_(8B)-Alpaca",
      "name": "Llama3.1_(8B)-Alpaca",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.1_(8B)-Alpaca.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.1_(8B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "huggingface course-llama3/HuggingFace Course-Llama3.1_(8B)-GRPO",
      "name": "Llama3.1_(8B)-GRPO",
      "description": "Fine-tune Huggingface Course Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Llama3.1_(8B)-GRPO.ipynb",
      "path": "huggingface course-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:39.266579+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Llama3.1_(8B)-GRPO.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.1_(8B)-GRPO",
      "name": "Llama3.1_(8B)-GRPO",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.1_(8B)-GRPO.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.1_(8B)-GRPO.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.1_(8B)-Inference",
      "name": "Llama3.1_(8B)-Inference",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.1_(8B)-Inference.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.1_(8B)-Inference.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.2_(11B)-Vision",
      "name": "Llama3.2_(11B)-Vision",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.2_(11B)-Vision.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.2_(11B)-Vision.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.2_(1B)-RAFT",
      "name": "Llama3.2_(1B)-RAFT",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.2_(1B)-RAFT.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.2_(1B)-RAFT.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.2_(1B_and_3B)-Conversational",
      "name": "Llama3.2_(1B_and_3B)-Conversational",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.2_(1B_and_3B)-Conversational.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.2_(1B_and_3B)-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3/Llama3.3_(70B)_A100-Conversational",
      "name": "Llama3.3_(70B)_A100-Conversational",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.3_(70B)_A100-Conversational.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:41.114374+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3.3_(70B)_A100-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3-8b/Llama3_(8B)-Alpaca",
      "name": "Llama3_(8B)-Alpaca",
      "description": "Fine-tune Llama3 (8B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Alpaca.ipynb",
      "path": "llama3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:41.326111+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3_(8B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "llama3-8b/Llama3_(8B)-Conversational",
      "name": "Llama3_(8B)-Conversational",
      "description": "Fine-tune Llama3 (8B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Conversational.ipynb",
      "path": "llama3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:41.326111+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3_(8B)-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3-8b-orpo/Llama3_(8B)-ORPO",
      "name": "Llama3_(8B)-ORPO",
      "description": "Fine-tune Llama3 (8B) Orpo with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-ORPO.ipynb",
      "path": "llama3-8b-orpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-ORPO.ipynb",
        "last_synced": "2025-10-23T06:07:39.552390+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3_(8B)-ORPO.ipynb"
      ]
    },
    {
      "id": "llama3-8b-ollama/Llama3_(8B)-Ollama",
      "name": "Llama3_(8B)-Ollama",
      "description": "Fine-tune Llama3 (8B) Ollama with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Ollama.ipynb",
      "path": "llama3-8b-ollama",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb",
        "last_synced": "2025-10-23T06:07:39.884393+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3_(8B)-Ollama.ipynb"
      ]
    },
    {
      "id": "llasa-tts-1b/Llasa_TTS_(1B)",
      "name": "Llasa_TTS_(1B)",
      "description": "Fine-tune Llasa Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Llasa_TTS_(1B).ipynb",
      "path": "llasa-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llasa_TTS_(1B).ipynb",
        "last_synced": "2025-10-23T06:07:40.474752+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llasa_TTS_(1B).ipynb"
      ]
    },
    {
      "id": "llasa-tts-3b/Llasa_TTS_(3B)",
      "name": "Llasa_TTS_(3B)",
      "description": "Fine-tune Llasa Tts (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Llasa_TTS_(3B).ipynb",
      "path": "llasa-tts-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llasa_TTS_(3B).ipynb",
        "last_synced": "2025-10-23T06:07:39.305199+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llasa_TTS_(3B).ipynb"
      ]
    },
    {
      "id": "lorawithtensorrt-llm/LoRAwithTensorRT-LLM",
      "name": "LoRAwithTensorRT-LLM",
      "description": "Fine-tune Lorawithtensorrt Llm with Unsloth on NVIDIA GPUs",
      "notebook": "LoRAwithTensorRT-LLM.ipynb",
      "path": "lorawithtensorrt-llm",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/LoRAwithTensorRT-LLM.ipynb",
        "last_synced": "2025-10-21T20:11:42.754935+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "LoRAwithTensorRT-LLM.ipynb"
      ]
    },
    {
      "id": "magistral-24b-reasoning/Magistral_(24B)-Reasoning-Conversational",
      "name": "Magistral_(24B)-Reasoning-Conversational",
      "description": "Fine-tune Magistral (24B) Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Magistral_(24B)-Reasoning-Conversational.ipynb",
      "path": "magistral-24b-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Magistral_(24B)-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:39.572070+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Magistral_(24B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "meta-synthetic-data-llama3/Meta-Synthetic-Data-Llama3.1_(8B)",
      "name": "Meta-Synthetic-Data-Llama3.1_(8B)",
      "description": "Fine-tune Meta Synthetic Data Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
      "path": "meta-synthetic-data-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Meta-Synthetic-Data-Llama3.ipynb",
        "last_synced": "2025-10-23T06:07:40.542850+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Meta-Synthetic-Data-Llama3.1_(8B).ipynb"
      ]
    },
    {
      "id": "meta-synthetic-data-llama3-2-3b/Meta_Synthetic_Data_Llama3_2_(3B)",
      "name": "Meta_Synthetic_Data_Llama3_2_(3B)",
      "description": "Fine-tune Meta Synthetic Data Llama3 2 (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
      "path": "meta-synthetic-data-llama3-2-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "last_synced": "2025-10-23T06:07:39.816935+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Meta_Synthetic_Data_Llama3_2_(3B).ipynb"
      ]
    },
    {
      "id": "mistral-7b-text-completion/Mistral_(7B)-Text_Completion",
      "name": "Mistral_(7B)-Text_Completion",
      "description": "Fine-tune Mistral (7B) Text Completion with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_(7B)-Text_Completion.ipynb",
      "path": "mistral-7b-text-completion",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb",
        "last_synced": "2025-10-23T06:07:40.904972+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_(7B)-Text_Completion.ipynb"
      ]
    },
    {
      "id": "mistral-nemo-12b/Mistral_Nemo_(12B)-Alpaca",
      "name": "Mistral_Nemo_(12B)-Alpaca",
      "description": "Fine-tune Mistral Nemo (12B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_Nemo_(12B)-Alpaca.ipynb",
      "path": "mistral-nemo-12b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_Nemo_(12B)-Alpaca.ipynb",
        "last_synced": "2025-10-23T06:07:40.215971+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_Nemo_(12B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "mistral-small-22b/Mistral_Small_(22B)-Alpaca",
      "name": "Mistral_Small_(22B)-Alpaca",
      "description": "Fine-tune Mistral Small (22B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_Small_(22B)-Alpaca.ipynb",
      "path": "mistral-small-22b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_Small_(22B)-Alpaca.ipynb",
        "last_synced": "2025-10-23T06:07:41.153892+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_Small_(22B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "mistral-v0/Mistral_v0.3_(7B)-Alpaca",
      "name": "Mistral_v0.3_(7B)-Alpaca",
      "description": "Fine-tune Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_v0.3_(7B)-Alpaca.ipynb",
      "path": "mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_v0.ipynb",
        "last_synced": "2025-10-23T06:07:41.246613+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_v0.3_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "mistral-v0/Mistral_v0.3_(7B)-CPT",
      "name": "Mistral_v0.3_(7B)-CPT",
      "description": "Fine-tune Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_v0.3_(7B)-CPT.ipynb",
      "path": "mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_v0.ipynb",
        "last_synced": "2025-10-23T06:07:41.246613+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_v0.3_(7B)-CPT.ipynb"
      ]
    },
    {
      "id": "mistral-v0/Mistral_v0.3_(7B)-Conversational",
      "name": "Mistral_v0.3_(7B)-Conversational",
      "description": "Fine-tune Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_v0.3_(7B)-Conversational.ipynb",
      "path": "mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_v0.ipynb",
        "last_synced": "2025-10-23T06:07:41.246613+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_v0.3_(7B)-Conversational.ipynb"
      ]
    },
    {
      "id": "huggingface course-mistral-v0/HuggingFace Course-Mistral_v0.3_(7B)-GRPO",
      "name": "Mistral_v0.3_(7B)-GRPO",
      "description": "Fine-tune Huggingface Course Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Mistral_v0.3_(7B)-GRPO.ipynb",
      "path": "huggingface course-mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Mistral_v0.ipynb",
        "last_synced": "2025-10-23T06:07:41.061823+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Mistral_v0.3_(7B)-GRPO.ipynb"
      ]
    },
    {
      "id": "mistral-v0/Mistral_v0.3_(7B)-GRPO",
      "name": "Mistral_v0.3_(7B)-GRPO",
      "description": "Fine-tune Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_v0.3_(7B)-GRPO.ipynb",
      "path": "mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_v0.ipynb",
        "last_synced": "2025-10-23T06:07:41.246613+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_v0.3_(7B)-GRPO.ipynb"
      ]
    },
    {
      "id": "orpheus-3b-tts/Orpheus_(3B)-TTS",
      "name": "Orpheus_(3B)-TTS",
      "description": "Fine-tune Orpheus (3B) Tts with Unsloth on NVIDIA GPUs",
      "notebook": "Orpheus_(3B)-TTS.ipynb",
      "path": "orpheus-3b-tts",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Orpheus_(3B)-TTS.ipynb",
        "last_synced": "2025-10-23T06:07:40.396274+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Orpheus_(3B)-TTS.ipynb"
      ]
    },
    {
      "id": "oute-tts-1b/Oute_TTS_(1B)",
      "name": "Oute_TTS_(1B)",
      "description": "Fine-tune Oute Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Oute_TTS_(1B).ipynb",
      "path": "oute-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Oute_TTS_(1B).ipynb",
        "last_synced": "2025-10-23T06:07:39.796243+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Oute_TTS_(1B).ipynb"
      ]
    },
    {
      "id": "phi-3/Phi_3.5_Mini-Conversational",
      "name": "Phi_3.5_Mini-Conversational",
      "description": "Fine-tune Phi 3 with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_3.5_Mini-Conversational.ipynb",
      "path": "phi-3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi_3.ipynb",
        "last_synced": "2025-10-23T06:07:41.306394+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_3.5_Mini-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-3-medium/Phi_3_Medium-Conversational",
      "name": "Phi_3_Medium-Conversational",
      "description": "Fine-tune Phi 3 Medium Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_3_Medium-Conversational.ipynb",
      "path": "phi-3-medium",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi_3_Medium-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:41.286437+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_3_Medium-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-4-14b-fine-tuning/Phi_4-Conversational",
      "name": "Phi_4-Conversational",
      "description": "Fine-tune Phi-4 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_4-Conversational.ipynb",
      "path": "phi-4-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi-4_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.345826+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_4-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-4-14b-fine-tuning/HuggingFace Course-Phi_4_(14B)-GRPO",
      "name": "Phi_4_(14B)-GRPO",
      "description": "Fine-tune Phi-4 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Phi_4_(14B)-GRPO.ipynb",
      "path": "phi-4-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi-4_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.345826+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Phi_4_(14B)-GRPO.ipynb"
      ]
    },
    {
      "id": "phi-4-14b-fine-tuning/Kaggle-Phi_4_(14B)-GRPO",
      "name": "Phi_4_(14B)-GRPO",
      "description": "Fine-tune Phi-4 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_4_(14B)-GRPO.ipynb",
      "path": "phi-4-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi-4_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.345826+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_4_(14B)-GRPO.ipynb"
      ]
    },
    {
      "id": "phi-4-14b-fine-tuning/Phi_4_(14B)-GRPO",
      "name": "Phi_4_(14B)-GRPO",
      "description": "Fine-tune Phi-4 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_4_(14B)-GRPO.ipynb",
      "path": "phi-4-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi-4_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.345826+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_4_(14B)-GRPO.ipynb"
      ]
    },
    {
      "id": "pixtral-12b-vision/Pixtral_(12B)-Vision",
      "name": "Pixtral_(12B)-Vision",
      "description": "Fine-tune Pixtral (12B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Pixtral_(12B)-Vision.ipynb",
      "path": "pixtral-12b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb",
        "last_synced": "2025-10-23T06:07:40.196341+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Pixtral_(12B)-Vision.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen2/HuggingFace Course-Qwen2.5_(3B)-GRPO",
      "name": "Qwen2.5_(3B)-GRPO",
      "description": "Fine-tune Huggingface Course Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen2.5_(3B)-GRPO.ipynb",
      "path": "huggingface course-qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen2.ipynb",
        "last_synced": "2025-10-23T06:07:39.974793+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Qwen2.5_(3B)-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen2/Qwen2.5_(3B)-GRPO",
      "name": "Qwen2.5_(3B)-GRPO",
      "description": "Fine-tune Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_(3B)-GRPO.ipynb",
      "path": "qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.ipynb",
        "last_synced": "2025-10-23T06:07:40.933678+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_(3B)-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen2/Qwen2.5_(7B)-Alpaca",
      "name": "Qwen2.5_(7B)-Alpaca",
      "description": "Fine-tune Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_(7B)-Alpaca.ipynb",
      "path": "qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.ipynb",
        "last_synced": "2025-10-23T06:07:40.933678+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "qwen2.5-coder-1/Qwen2.5_Coder_(1.5B)-Tool_Calling",
      "name": "Qwen2.5_Coder_(1.5B)-Tool_Calling",
      "description": "Fine-tune Qwen2.5 Coder (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
      "path": "qwen2.5-coder-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_(1.ipynb",
        "last_synced": "2025-10-23T06:07:39.529167+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb"
      ]
    },
    {
      "id": "qwen2/Qwen2.5_Coder_(14B)-Conversational",
      "name": "Qwen2.5_Coder_(14B)-Conversational",
      "description": "Fine-tune Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_Coder_(14B)-Conversational.ipynb",
      "path": "qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.ipynb",
        "last_synced": "2025-10-23T06:07:40.933678+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_Coder_(14B)-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen2/Qwen2.5_VL_(7B)-Vision",
      "name": "Qwen2.5_VL_(7B)-Vision",
      "description": "Fine-tune Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_VL_(7B)-Vision.ipynb",
      "path": "qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.ipynb",
        "last_synced": "2025-10-23T06:07:40.933678+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_VL_(7B)-Vision.ipynb"
      ]
    },
    {
      "id": "qwen2-7b/Qwen2_(7B)-Alpaca",
      "name": "Qwen2_(7B)-Alpaca",
      "description": "Fine-tune Qwen2 (7B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_(7B)-Alpaca.ipynb",
      "path": "qwen2-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_(7B)-Alpaca.ipynb",
        "last_synced": "2025-10-23T06:07:40.640990+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "qwen2-5-7b-vl/Qwen2_5_7B_VL_GRPO",
      "name": "Qwen2_5_7B_VL_GRPO",
      "description": "Fine-tune Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:39.736057+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2_5_7B_VL_GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen2-5-7b-vl/HuggingFace Course-Qwen2_5_7B_VL_GRPO",
      "name": "Qwen2_5_7B_VL_GRPO",
      "description": "Fine-tune Huggingface Course Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "huggingface course-qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:41.419284+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb"
      ]
    },
    {
      "id": "qwen2-vl-7b-vision/Qwen2_VL_(7B)-Vision",
      "name": "Qwen2_VL_(7B)-Vision",
      "description": "Fine-tune Qwen2 Vl (7B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_VL_(7B)-Vision.ipynb",
      "path": "qwen2-vl-7b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb",
        "last_synced": "2025-10-23T06:07:39.466275+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2_VL_(7B)-Vision.ipynb"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning/Kaggle-Qwen3_(14B)",
      "name": "Qwen3_(14B)",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(14B).ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.460497+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(14B).ipynb"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning/Qwen3_(14B)",
      "name": "Qwen3_(14B)",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(14B).ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.460497+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(14B).ipynb"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning/Kaggle-Qwen3_(14B)-Alpaca",
      "name": "Qwen3_(14B)-Alpaca",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(14B)-Alpaca.ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.460497+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(14B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning/Qwen3_(14B)-Alpaca",
      "name": "Qwen3_(14B)-Alpaca",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(14B)-Alpaca.ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.460497+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(14B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning/Kaggle-Qwen3_(14B)-Reasoning-Conversational",
      "name": "Qwen3_(14B)-Reasoning-Conversational",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(14B)-Reasoning-Conversational.ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.460497+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(14B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning/Qwen3_(14B)-Reasoning-Conversational",
      "name": "Qwen3_(14B)-Reasoning-Conversational",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(14B)-Reasoning-Conversational.ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-23T06:07:41.460497+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(14B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-32b-a100-reasoning/Qwen3_(32B)_A100-Reasoning-Conversational",
      "name": "Qwen3_(32B)_A100-Reasoning-Conversational",
      "description": "Fine-tune Qwen3 (32B) A100 Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
      "path": "qwen3-32b-a100-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-23T06:07:40.838729+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(32B)_A100-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-grpo-rl/Qwen3_(4B)-GRPO",
      "name": "Qwen3_(4B)-GRPO",
      "description": "Fine-tune Qwen3 (4B) GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-GRPO.ipynb",
      "path": "qwen3-4b-grpo-rl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reinforcement-learning",
        "grpo",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)_grpo.ipynb",
        "last_synced": "2025-10-23T06:07:41.490619+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen3-4b/HuggingFace Course-Qwen3_(4B)-GRPO",
      "name": "Qwen3_(4B)-GRPO",
      "description": "Fine-tune Huggingface Course Qwen3 (4B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
      "path": "huggingface course-qwen3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
        "last_synced": "2025-10-23T06:07:40.284646+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Qwen3_(4B)-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-instruct/Qwen3_(4B)-Instruct",
      "name": "Qwen3_(4B)-Instruct",
      "description": "Fine-tune Qwen3 (4B) Instruct with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-Instruct.ipynb",
      "path": "qwen3-4b-instruct",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-Instruct.ipynb",
        "last_synced": "2025-10-23T06:07:41.174389+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-Instruct.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-thinking/Qwen3_(4B)-Thinking",
      "name": "Qwen3_(4B)-Thinking",
      "description": "Fine-tune Qwen3 (4B) Thinking with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-Thinking.ipynb",
      "path": "qwen3-4b-thinking",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-Thinking.ipynb",
        "last_synced": "2025-10-23T06:07:40.755279+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-Thinking.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-instruct-qat/Qwen3_(4B)_Instruct-QAT",
      "name": "Qwen3_(4B)_Instruct-QAT",
      "description": "Fine-tune Qwen3 (4B) Instruct Qat with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)_Instruct-QAT.ipynb",
      "path": "qwen3-4b-instruct-qat",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)_Instruct-QAT.ipynb",
        "last_synced": "2025-10-23T06:07:40.433932+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)_Instruct-QAT.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision/Kaggle-Qwen3_VL_(8B)-Vision",
      "name": "Qwen3_VL_(8B)-Vision",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_VL_(8B)-Vision.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-23T06:07:41.437799+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_VL_(8B)-Vision.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision/Qwen3_VL_(8B)-Vision",
      "name": "Qwen3_VL_(8B)-Vision",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_VL_(8B)-Vision.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-23T06:07:41.437799+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_VL_(8B)-Vision.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision/HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO",
      "name": "Qwen3_VL_(8B)-Vision-GRPO",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-23T06:07:41.437799+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision/Kaggle-Qwen3_VL_(8B)-Vision-GRPO",
      "name": "Qwen3_VL_(8B)-Vision-GRPO",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-23T06:07:41.437799+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_VL_(8B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision/Qwen3_VL_(8B)-Vision-GRPO",
      "name": "Qwen3_VL_(8B)-Vision-GRPO",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_VL_(8B)-Vision-GRPO.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-23T06:07:41.437799+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_VL_(8B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "rag-with-local-nim-v2/RAG_WIth_Local_NIM_V2",
      "name": "RAG_WIth_Local_NIM_V2",
      "description": "Fine-tune Rag With Local Nim V2 with Unsloth on NVIDIA GPUs",
      "notebook": "RAG_WIth_Local_NIM_V2.ipynb",
      "path": "rag-with-local-nim-v2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/RAG_WIth_Local_NIM_V2.ipynb",
        "last_synced": "2025-10-21T20:11:41.778428+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "RAG_WIth_Local_NIM_V2.ipynb"
      ]
    },
    {
      "id": "sesame-csm-1b-tts/Kaggle-Sesame_CSM_(1B)-TTS",
      "name": "Sesame_CSM_(1B)-TTS",
      "description": "Fine-tune Sesame-CSM (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Sesame_CSM_(1B)-TTS.ipynb",
      "path": "sesame-csm-1b-tts",
      "gpu": {
        "tier": "T4",
        "min_vram_gb": 12,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "text-to-speech",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Sesame-CSM_(1B).ipynb",
        "last_synced": "2025-10-23T06:07:39.660495+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Sesame_CSM_(1B)-TTS.ipynb"
      ]
    },
    {
      "id": "sesame-csm-1b-tts/Sesame_CSM_(1B)-TTS",
      "name": "Sesame_CSM_(1B)-TTS",
      "description": "Fine-tune Sesame-CSM (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Sesame_CSM_(1B)-TTS.ipynb",
      "path": "sesame-csm-1b-tts",
      "gpu": {
        "tier": "T4",
        "min_vram_gb": 12,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "text-to-speech",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Sesame-CSM_(1B).ipynb",
        "last_synced": "2025-10-23T06:07:39.660495+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Sesame_CSM_(1B)-TTS.ipynb"
      ]
    },
    {
      "id": "spark-tts-0-5b/Spark_TTS_(0_5B)",
      "name": "Spark_TTS_(0_5B)",
      "description": "Fine-tune Spark Tts (0 5B) with Unsloth on NVIDIA GPUs",
      "notebook": "Spark_TTS_(0_5B).ipynb",
      "path": "spark-tts-0-5b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Spark_TTS_(0_5B).ipynb",
        "last_synced": "2025-10-23T06:07:40.561922+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Spark_TTS_(0_5B).ipynb"
      ]
    },
    {
      "id": "synthetic-data-hackathon/Synthetic_Data_Hackathon",
      "name": "Synthetic_Data_Hackathon",
      "description": "Fine-tune Synthetic Data Hackathon with Unsloth on NVIDIA GPUs",
      "notebook": "Synthetic_Data_Hackathon.ipynb",
      "path": "synthetic-data-hackathon",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Synthetic_Data_Hackathon.ipynb",
        "last_synced": "2025-10-23T06:07:41.100823+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Synthetic_Data_Hackathon.ipynb"
      ]
    },
    {
      "id": "tinyllama-1/TinyLlama_(1.1B)-Alpaca",
      "name": "TinyLlama_(1.1B)-Alpaca",
      "description": "Fine-tune Tinyllama (1 with Unsloth on NVIDIA GPUs",
      "notebook": "TinyLlama_(1.1B)-Alpaca.ipynb",
      "path": "tinyllama-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/TinyLlama_(1.ipynb",
        "last_synced": "2025-10-23T06:07:39.373553+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "TinyLlama_(1.1B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "unsloth-studio/Unsloth_Studio",
      "name": "Unsloth_Studio",
      "description": "Fine-tune Unsloth Studio with Unsloth on NVIDIA GPUs",
      "notebook": "Unsloth_Studio.ipynb",
      "path": "unsloth-studio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb",
        "last_synced": "2025-10-23T06:07:39.504755+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Unsloth_Studio.ipynb"
      ]
    },
    {
      "id": "whisper-large-v3-stt/Whisper",
      "name": "Whisper",
      "description": "Fine-tune Whisper Large V3 with Unsloth on NVIDIA GPUs",
      "notebook": "Whisper.ipynb",
      "path": "whisper-large-v3-stt",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "speech-to-text",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Whisper_Large_V3.ipynb",
        "last_synced": "2025-10-23T06:07:39.710221+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Whisper.ipynb"
      ]
    },
    {
      "id": "zephyr-7b-dpo/Zephyr_(7B)-DPO",
      "name": "Zephyr_(7B)-DPO",
      "description": "Fine-tune Zephyr (7B) Dpo with Unsloth on NVIDIA GPUs",
      "notebook": "Zephyr_(7B)-DPO.ipynb",
      "path": "zephyr-7b-dpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Zephyr_(7B)-DPO.ipynb",
        "last_synced": "2025-10-23T06:07:40.997866+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Zephyr_(7B)-DPO.ipynb"
      ]
    },
    {
      "id": "ara/ara",
      "name": "ara",
      "description": "Fine-tune Ara with Unsloth on NVIDIA GPUs",
      "notebook": "ara.ipynb",
      "path": "ara",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/ara.ipynb",
        "last_synced": "2025-10-21T20:11:42.878054+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "ara.ipynb"
      ]
    },
    {
      "id": "automatic1111-stable-diffusion-ui/automatic1111-stable-diffusion-ui",
      "name": "automatic1111-stable-diffusion-ui",
      "description": "Fine-tune Automatic1111 Stable Diffusion Ui with Unsloth on NVIDIA GPUs",
      "notebook": "automatic1111-stable-diffusion-ui.ipynb",
      "path": "automatic1111-stable-diffusion-ui",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/automatic1111-stable-diffusion-ui.ipynb",
        "last_synced": "2025-10-21T20:11:41.810700+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "automatic1111-stable-diffusion-ui.ipynb"
      ]
    },
    {
      "id": "baklava/baklava",
      "name": "baklava",
      "description": "Fine-tune Baklava with Unsloth on NVIDIA GPUs",
      "notebook": "baklava.ipynb",
      "path": "baklava",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/baklava.ipynb",
        "last_synced": "2025-10-21T20:11:42.745606+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "baklava.ipynb"
      ]
    },
    {
      "id": "bert-classification/bert_classification",
      "name": "bert_classification",
      "description": "Fine-tune Bert Classification with Unsloth on NVIDIA GPUs",
      "notebook": "bert_classification.ipynb",
      "path": "bert-classification",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/bert_classification.ipynb",
        "last_synced": "2025-10-23T06:07:39.776171+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "bert_classification.ipynb"
      ]
    },
    {
      "id": "biomistral/biomistral",
      "name": "biomistral",
      "description": "Fine-tune Biomistral with Unsloth on NVIDIA GPUs",
      "notebook": "biomistral.ipynb",
      "path": "biomistral",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/biomistral.ipynb",
        "last_synced": "2025-10-21T20:11:42.587933+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "biomistral.ipynb"
      ]
    },
    {
      "id": "biomistral-finetune/biomistral-finetune",
      "name": "biomistral-finetune",
      "description": "Fine-tune Biomistral Finetune with Unsloth on NVIDIA GPUs",
      "notebook": "biomistral-finetune.ipynb",
      "path": "biomistral-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/biomistral-finetune.ipynb",
        "last_synced": "2025-10-21T20:11:42.618314+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "biomistral-finetune.ipynb"
      ]
    },
    {
      "id": "caltech-protein-demo/caltech-protein-demo",
      "name": "caltech-protein-demo",
      "description": "Fine-tune Caltech Protein Demo with Unsloth on NVIDIA GPUs",
      "notebook": "caltech-protein-demo.ipynb",
      "path": "caltech-protein-demo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/caltech-protein-demo.ipynb",
        "last_synced": "2025-10-21T20:11:42.420561+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "caltech-protein-demo.ipynb"
      ]
    },
    {
      "id": "comfyui/comfyui",
      "name": "comfyui",
      "description": "Fine-tune Comfyui with Unsloth on NVIDIA GPUs",
      "notebook": "comfyui.ipynb",
      "path": "comfyui",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/comfyui.ipynb",
        "last_synced": "2025-10-21T20:11:42.442129+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "comfyui.ipynb"
      ]
    },
    {
      "id": "container-vulnerability-analysis/container_vulnerability_analysis",
      "name": "container_vulnerability_analysis",
      "description": "Fine-tune Container Vulnerability Analysis with Unsloth on NVIDIA GPUs",
      "notebook": "container_vulnerability_analysis.ipynb",
      "path": "container-vulnerability-analysis",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/container_vulnerability_analysis.ipynb",
        "last_synced": "2025-10-21T20:11:42.767364+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "container_vulnerability_analysis.ipynb"
      ]
    },
    {
      "id": "controlnet/controlnet",
      "name": "controlnet",
      "description": "Fine-tune Controlnet with Unsloth on NVIDIA GPUs",
      "notebook": "controlnet.ipynb",
      "path": "controlnet",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/controlnet.ipynb",
        "last_synced": "2025-10-21T20:11:42.836828+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "controlnet.ipynb"
      ]
    },
    {
      "id": "dbrx/dbrx_inference",
      "name": "dbrx_inference",
      "description": "Fine-tune Dbrx Inference with Unsloth on NVIDIA GPUs",
      "notebook": "dbrx_inference.ipynb",
      "path": "dbrx",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/dbrx_inference.ipynb",
        "last_synced": "2025-10-21T20:11:41.860194+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "dbrx_inference.ipynb"
      ]
    },
    {
      "id": "deploy-to-replicate/deploy-to-replicate",
      "name": "deploy-to-replicate",
      "description": "Fine-tune Deploy To Replicate with Unsloth on NVIDIA GPUs",
      "notebook": "deploy-to-replicate.ipynb",
      "path": "deploy-to-replicate",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/deploy-to-replicate.ipynb",
        "last_synced": "2025-10-21T20:11:42.369729+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "deploy-to-replicate.ipynb"
      ]
    },
    {
      "id": "diffusion-lora/diffusion_lora_inference",
      "name": "diffusion_lora_inference",
      "description": "Fine-tune Diffusion Lora Inference with Unsloth on NVIDIA GPUs",
      "notebook": "diffusion_lora_inference.ipynb",
      "path": "diffusion-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/diffusion_lora_inference.ipynb",
        "last_synced": "2025-10-21T20:11:42.144638+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "diffusion_lora_inference.ipynb"
      ]
    },
    {
      "id": "efficientvit-segmentation/efficientvit-segmentation",
      "name": "efficientvit-segmentation",
      "description": "Fine-tune Efficientvit Segmentation with Unsloth on NVIDIA GPUs",
      "notebook": "efficientvit-segmentation.ipynb",
      "path": "efficientvit-segmentation",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/efficientvit-segmentation.ipynb",
        "last_synced": "2025-10-21T20:11:42.399716+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "efficientvit-segmentation.ipynb"
      ]
    },
    {
      "id": "gemma7b/gemma7b",
      "name": "gemma7b",
      "description": "Fine-tune Gemma7B with Unsloth on NVIDIA GPUs",
      "notebook": "gemma7b.ipynb",
      "path": "gemma7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gemma7b.ipynb",
        "last_synced": "2025-10-21T20:11:42.726339+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gemma7b.ipynb"
      ]
    },
    {
      "id": "gguf-export/gguf-export",
      "name": "gguf-export",
      "description": "Fine-tune Gguf Export with Unsloth on NVIDIA GPUs",
      "notebook": "gguf-export.ipynb",
      "path": "gguf-export",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gguf-export.ipynb",
        "last_synced": "2025-10-21T20:11:42.351221+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gguf-export.ipynb"
      ]
    },
    {
      "id": "gpt-oss-120b-fine-tuning/Kaggle-gpt-oss-(120B)_A100-Fine-tuning",
      "name": "gpt-oss-(120B)_A100-Fine-tuning",
      "description": "Fine-tune gpt-oss-120b with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-gpt-oss-(120B)_A100-Fine-tuning.ipynb",
      "path": "gpt-oss-120b-fine-tuning",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 80,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-120b.ipynb",
        "last_synced": "2025-10-23T06:07:39.861614+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(120B)_A100-Fine-tuning.ipynb"
      ]
    },
    {
      "id": "gpt-oss-120b-fine-tuning/gpt-oss-(120B)_A100-Fine-tuning",
      "name": "gpt-oss-(120B)_A100-Fine-tuning",
      "description": "Fine-tune gpt-oss-120b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt-oss-(120B)_A100-Fine-tuning.ipynb",
      "path": "gpt-oss-120b-fine-tuning",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 80,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-120b.ipynb",
        "last_synced": "2025-10-23T06:07:39.861614+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt-oss-(120B)_A100-Fine-tuning.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/Kaggle-gpt-oss-(20B)-Fine-tuning",
      "name": "gpt-oss-(20B)-Fine-tuning",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-gpt-oss-(20B)-Fine-tuning.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(20B)-Fine-tuning.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/gpt-oss-(20B)-Fine-tuning",
      "name": "gpt-oss-(20B)-Fine-tuning",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt-oss-(20B)-Fine-tuning.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt-oss-(20B)-Fine-tuning.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/HuggingFace Course-gpt-oss-(20B)-GRPO",
      "name": "gpt-oss-(20B)-GRPO",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-gpt-oss-(20B)-GRPO.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-gpt-oss-(20B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/Kaggle-gpt-oss-(20B)-GRPO",
      "name": "gpt-oss-(20B)-GRPO",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-gpt-oss-(20B)-GRPO.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(20B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/gpt-oss-(20B)-GRPO",
      "name": "gpt-oss-(20B)-GRPO",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt-oss-(20B)-GRPO.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt-oss-(20B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/HuggingFace Course-gpt-oss-(20B)_A100-GRPO",
      "name": "gpt-oss-(20B)_A100-GRPO",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-gpt-oss-(20B)_A100-GRPO.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-gpt-oss-(20B)_A100-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/Kaggle-gpt-oss-(20B)_A100-GRPO",
      "name": "gpt-oss-(20B)_A100-GRPO",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-gpt-oss-(20B)_A100-GRPO.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(20B)_A100-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/gpt-oss-(20B)_A100-GRPO",
      "name": "gpt-oss-(20B)_A100-GRPO",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt-oss-(20B)_A100-GRPO.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt-oss-(20B)_A100-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-grpo-rl/HuggingFace Course-gpt_oss_(20B)_GRPO_BF16",
      "name": "gpt_oss_(20B)_GRPO_BF16",
      "description": "Fine-tune gpt-oss-20b-GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-gpt_oss_(20B)_GRPO_BF16.ipynb",
      "path": "gpt-oss-20b-grpo-rl",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 40,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "reinforcement-learning",
        "grpo"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b-grpo.ipynb",
        "last_synced": "2025-10-23T06:07:40.863827+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-gpt_oss_(20B)_GRPO_BF16.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-grpo-rl/gpt_oss_(20B)_GRPO_BF16",
      "name": "gpt_oss_(20B)_GRPO_BF16",
      "description": "Fine-tune gpt-oss-20b-GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_GRPO_BF16.ipynb",
      "path": "gpt-oss-20b-grpo-rl",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 40,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "reinforcement-learning",
        "grpo"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b-grpo.ipynb",
        "last_synced": "2025-10-23T06:07:40.863827+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt_oss_(20B)_GRPO_BF16.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/gpt_oss_(20B)_Reinforcement_Learning_2048_Game",
      "name": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/gpt_oss_(20B)_Reinforcement_Learning_2048_Game_BF16",
      "name": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_BF16",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_BF16.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_BF16.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning/gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark",
      "name": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-23T06:07:41.515128+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark.ipynb"
      ]
    },
    {
      "id": "julia-install/julia-install",
      "name": "julia-install",
      "description": "Fine-tune Julia Install with Unsloth on NVIDIA GPUs",
      "notebook": "julia-install.ipynb",
      "path": "julia-install",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/julia-install.ipynb",
        "last_synced": "2025-10-21T20:11:42.646625+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "julia-install.ipynb"
      ]
    },
    {
      "id": "llama2/llama2",
      "name": "llama2",
      "description": "Fine-tune Llama2 with Unsloth on NVIDIA GPUs",
      "notebook": "llama2.ipynb",
      "path": "llama2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama2.ipynb",
        "last_synced": "2025-10-21T20:11:42.281701+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama2.ipynb"
      ]
    },
    {
      "id": "llama2-finetune/llama2-finetune",
      "name": "llama2-finetune",
      "description": "Fine-tune Llama2 Finetune with Unsloth on NVIDIA GPUs",
      "notebook": "llama2-finetune.ipynb",
      "path": "llama2-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama2-finetune.ipynb",
        "last_synced": "2025-10-21T20:11:41.933303+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama2-finetune.ipynb"
      ]
    },
    {
      "id": "llama2-finetune-own-data/llama2-finetune-own-data",
      "name": "llama2-finetune-own-data",
      "description": "Fine-tune Llama2 Finetune Own Data with Unsloth on NVIDIA GPUs",
      "notebook": "llama2-finetune-own-data.ipynb",
      "path": "llama2-finetune-own-data",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama2-finetune-own-data.ipynb",
        "last_synced": "2025-10-21T20:11:42.657873+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama2-finetune-own-data.ipynb"
      ]
    },
    {
      "id": "llama3-to-ollama/llama3-to-ollama",
      "name": "llama3-to-ollama",
      "description": "Fine-tune Llama3 To Ollama with Unsloth on NVIDIA GPUs",
      "notebook": "llama3-to-ollama.ipynb",
      "path": "llama3-to-ollama",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama3-to-ollama.ipynb",
        "last_synced": "2025-10-21T20:11:42.857513+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama3-to-ollama.ipynb"
      ]
    },
    {
      "id": "llama31-law/llama31_law",
      "name": "llama31_law",
      "description": "Fine-tune Llama31 Law with Unsloth on NVIDIA GPUs",
      "notebook": "llama31_law.ipynb",
      "path": "llama31-law",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama31_law.ipynb",
        "last_synced": "2025-10-21T20:11:42.690357+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama31_law.ipynb"
      ]
    },
    {
      "id": "llama3-finetune/llama3_finetune_inference",
      "name": "llama3_finetune_inference",
      "description": "Fine-tune Llama3 Finetune Inference with Unsloth on NVIDIA GPUs",
      "notebook": "llama3_finetune_inference.ipynb",
      "path": "llama3-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama3_finetune_inference.ipynb",
        "last_synced": "2025-10-21T20:11:42.408888+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama3_finetune_inference.ipynb"
      ]
    },
    {
      "id": "llama3dpo/llama3dpo",
      "name": "llama3dpo",
      "description": "Fine-tune Llama3Dpo with Unsloth on NVIDIA GPUs",
      "notebook": "llama3dpo.ipynb",
      "path": "llama3dpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llama3dpo.ipynb",
        "last_synced": "2025-10-21T20:11:43.029067+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llama3dpo.ipynb"
      ]
    },
    {
      "id": "llava-finetune/llava-finetune",
      "name": "llava-finetune",
      "description": "Fine-tune Llava Finetune with Unsloth on NVIDIA GPUs",
      "notebook": "llava-finetune.ipynb",
      "path": "llava-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/llava-finetune.ipynb",
        "last_synced": "2025-10-21T20:11:42.511977+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "llava-finetune.ipynb"
      ]
    },
    {
      "id": "meta-chameleon-model/meta-chameleon-model",
      "name": "meta-chameleon-model",
      "description": "Fine-tune Meta Chameleon Model with Unsloth on NVIDIA GPUs",
      "notebook": "meta-chameleon-model.ipynb",
      "path": "meta-chameleon-model",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/meta-chameleon-model.ipynb",
        "last_synced": "2025-10-21T20:11:42.469662+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "meta-chameleon-model.ipynb"
      ]
    },
    {
      "id": "mistral-finetune/mistral-finetune",
      "name": "mistral-finetune",
      "description": "Fine-tune Mistral Finetune with Unsloth on NVIDIA GPUs",
      "notebook": "mistral-finetune.ipynb",
      "path": "mistral-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/mistral-finetune.ipynb",
        "last_synced": "2025-10-21T20:11:42.454560+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "mistral-finetune.ipynb"
      ]
    },
    {
      "id": "mistral-finetune-nemo/mistral-finetune-nemo",
      "name": "mistral-finetune-nemo",
      "description": "Fine-tune Mistral Finetune Nemo with Unsloth on NVIDIA GPUs",
      "notebook": "mistral-finetune-nemo.ipynb",
      "path": "mistral-finetune-nemo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/mistral-finetune-nemo.ipynb",
        "last_synced": "2025-10-21T20:11:42.336759+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "mistral-finetune-nemo.ipynb"
      ]
    },
    {
      "id": "mistral-finetune-own-data/mistral-finetune-own-data",
      "name": "mistral-finetune-own-data",
      "description": "Fine-tune Mistral Finetune Own Data with Unsloth on NVIDIA GPUs",
      "notebook": "mistral-finetune-own-data.ipynb",
      "path": "mistral-finetune-own-data",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/mistral-finetune-own-data.ipynb",
        "last_synced": "2025-10-21T20:11:42.182769+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "mistral-finetune-own-data.ipynb"
      ]
    },
    {
      "id": "mixtral-finetune/mixtral-finetune",
      "name": "mixtral-finetune",
      "description": "Fine-tune Mixtral Finetune with Unsloth on NVIDIA GPUs",
      "notebook": "mixtral-finetune.ipynb",
      "path": "mixtral-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/mixtral-finetune.ipynb",
        "last_synced": "2025-10-21T20:11:42.900574+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "mixtral-finetune.ipynb"
      ]
    },
    {
      "id": "mixtral-finetune-own-data/mixtral-finetune-own-data",
      "name": "mixtral-finetune-own-data",
      "description": "Fine-tune Mixtral Finetune Own Data with Unsloth on NVIDIA GPUs",
      "notebook": "mixtral-finetune-own-data.ipynb",
      "path": "mixtral-finetune-own-data",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/mixtral-finetune-own-data.ipynb",
        "last_synced": "2025-10-21T20:11:42.324318+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "mixtral-finetune-own-data.ipynb"
      ]
    },
    {
      "id": "molmim-optimization/molmim-optimization",
      "name": "molmim-optimization",
      "description": "Fine-tune Molmim Optimization with Unsloth on NVIDIA GPUs",
      "notebook": "molmim-optimization.ipynb",
      "path": "molmim-optimization",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/molmim-optimization.ipynb",
        "last_synced": "2025-10-21T20:11:42.735914+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "molmim-optimization.ipynb"
      ]
    },
    {
      "id": "nemo-reranker/nemo-reranker",
      "name": "nemo-reranker",
      "description": "Fine-tune Nemo Reranker with Unsloth on NVIDIA GPUs",
      "notebook": "nemo-reranker.ipynb",
      "path": "nemo-reranker",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/nemo-reranker.ipynb",
        "last_synced": "2025-10-21T20:11:42.868082+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "nemo-reranker.ipynb"
      ]
    },
    {
      "id": "nim-quickstart/nim-quickstart",
      "name": "nim-quickstart",
      "description": "Fine-tune Nim Quickstart with Unsloth on NVIDIA GPUs",
      "notebook": "nim-quickstart.ipynb",
      "path": "nim-quickstart",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/nim-quickstart.ipynb",
        "last_synced": "2025-10-21T20:11:42.824508+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "nim-quickstart.ipynb"
      ]
    },
    {
      "id": "nvidia-nim-agents-llama3/nvidia_nim_agents_llama3.1",
      "name": "nvidia_nim_agents_llama3.1",
      "description": "Fine-tune Nvidia Nim Agents Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "nvidia_nim_agents_llama3.1.ipynb",
      "path": "nvidia-nim-agents-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/nvidia_nim_agents_llama3.ipynb",
        "last_synced": "2025-10-21T20:11:42.123589+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "nvidia_nim_agents_llama3.1.ipynb"
      ]
    },
    {
      "id": "ocr-pdf-analysis/ocr-pdf-analysis",
      "name": "ocr-pdf-analysis",
      "description": "Fine-tune Ocr Pdf Analysis with Unsloth on NVIDIA GPUs",
      "notebook": "ocr-pdf-analysis.ipynb",
      "path": "ocr-pdf-analysis",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/ocr-pdf-analysis.ipynb",
        "last_synced": "2025-10-21T20:11:41.880153+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "ocr-pdf-analysis.ipynb"
      ]
    },
    {
      "id": "oobabooga/oobabooga",
      "name": "oobabooga",
      "description": "Fine-tune Oobabooga with Unsloth on NVIDIA GPUs",
      "notebook": "oobabooga.ipynb",
      "path": "oobabooga",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/oobabooga.ipynb",
        "last_synced": "2025-10-21T20:11:42.676737+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "oobabooga.ipynb"
      ]
    },
    {
      "id": "pdf-blueprint/pdf-blueprint",
      "name": "pdf-blueprint",
      "description": "Fine-tune Pdf Blueprint with Unsloth on NVIDIA GPUs",
      "notebook": "pdf-blueprint.ipynb",
      "path": "pdf-blueprint",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/pdf-blueprint.ipynb",
        "last_synced": "2025-10-21T20:11:42.794584+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "pdf-blueprint.ipynb"
      ]
    },
    {
      "id": "phi2-finetune/phi2-finetune",
      "name": "phi2-finetune",
      "description": "Fine-tune Phi2 Finetune with Unsloth on NVIDIA GPUs",
      "notebook": "phi2-finetune.ipynb",
      "path": "phi2-finetune",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/phi2-finetune.ipynb",
        "last_synced": "2025-10-21T20:11:42.207901+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "phi2-finetune.ipynb"
      ]
    },
    {
      "id": "phi2-finetune-own-data/phi2-finetune-own-data",
      "name": "phi2-finetune-own-data",
      "description": "Fine-tune Phi2 Finetune Own Data with Unsloth on NVIDIA GPUs",
      "notebook": "phi2-finetune-own-data.ipynb",
      "path": "phi2-finetune-own-data",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/phi2-finetune-own-data.ipynb",
        "last_synced": "2025-10-21T20:11:42.812058+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "phi2-finetune-own-data.ipynb"
      ]
    },
    {
      "id": "question-answer-nemo/question_answer_nemo",
      "name": "question_answer_nemo",
      "description": "Fine-tune Question Answer Nemo with Unsloth on NVIDIA GPUs",
      "notebook": "question_answer_nemo.ipynb",
      "path": "question-answer-nemo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/question_answer_nemo.ipynb",
        "last_synced": "2025-10-21T20:11:42.704720+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "question_answer_nemo.ipynb"
      ]
    },
    {
      "id": "rapids-cudf-pandas/rapids_cudf_pandas",
      "name": "rapids_cudf_pandas",
      "description": "Fine-tune Rapids Cudf Pandas with Unsloth on NVIDIA GPUs",
      "notebook": "rapids_cudf_pandas.ipynb",
      "path": "rapids-cudf-pandas",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/rapids_cudf_pandas.ipynb",
        "last_synced": "2025-10-21T20:11:42.494882+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "rapids_cudf_pandas.ipynb"
      ]
    },
    {
      "id": "setup-k8s/setup-k8s",
      "name": "setup-k8s",
      "description": "Fine-tune Setup K8S with Unsloth on NVIDIA GPUs",
      "notebook": "setup-k8s.ipynb",
      "path": "setup-k8s",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/setup-k8s.ipynb",
        "last_synced": "2025-10-21T20:11:42.847472+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "setup-k8s.ipynb"
      ]
    },
    {
      "id": "streamingllm-tensorrt/streamingllm-tensorrt",
      "name": "streamingllm-tensorrt",
      "description": "Fine-tune Streamingllm Tensorrt with Unsloth on NVIDIA GPUs",
      "notebook": "streamingllm-tensorrt.ipynb",
      "path": "streamingllm-tensorrt",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/streamingllm-tensorrt.ipynb",
        "last_synced": "2025-10-21T20:11:42.716161+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "streamingllm-tensorrt.ipynb"
      ]
    },
    {
      "id": "tensorrt-comfyui/tensorrt-comfyui",
      "name": "tensorrt-comfyui",
      "description": "Fine-tune Tensorrt Comfyui with Unsloth on NVIDIA GPUs",
      "notebook": "tensorrt-comfyui.ipynb",
      "path": "tensorrt-comfyui",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/tensorrt-comfyui.ipynb",
        "last_synced": "2025-10-21T20:11:42.390171+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "tensorrt-comfyui.ipynb"
      ]
    },
    {
      "id": "tensorrt-llama3/tensorrt-llama3",
      "name": "tensorrt-llama3",
      "description": "Fine-tune Tensorrt Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "tensorrt-llama3.ipynb",
      "path": "tensorrt-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/tensorrt-llama3.ipynb",
        "last_synced": "2025-10-21T20:11:42.292115+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "tensorrt-llama3.ipynb"
      ]
    },
    {
      "id": "tensorrt-mistral/tensorrt_mistral",
      "name": "tensorrt_mistral",
      "description": "Fine-tune Tensorrt Mistral with Unsloth on NVIDIA GPUs",
      "notebook": "tensorrt_mistral.ipynb",
      "path": "tensorrt-mistral",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/tensorrt_mistral.ipynb",
        "last_synced": "2025-10-21T20:11:41.844379+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "tensorrt_mistral.ipynb"
      ]
    },
    {
      "id": "zephyr-chatbot/zephyr-chatbot",
      "name": "zephyr-chatbot",
      "description": "Fine-tune Zephyr Chatbot with Unsloth on NVIDIA GPUs",
      "notebook": "zephyr-chatbot.ipynb",
      "path": "zephyr-chatbot",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/zephyr-chatbot.ipynb",
        "last_synced": "2025-10-21T20:11:42.433139+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "zephyr-chatbot.ipynb"
      ]
    }
  ]
}