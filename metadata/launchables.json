{
  "version": "1.0.0",
  "generated_at": "2025-10-21T16:20:19.336323+00:00",
  "total_launchables": 129,
  "launchables": [
    {
      "id": "advanced-llama3-1-3b-grpo-lora",
      "name": "Advanced Llama3 1 (3B) Grpo Lora",
      "description": "Fine-tune Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:20:12.523121+00:00"
      },
      "files": [
        "Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "advanced-llama3-2-3b-grpo-lora",
      "name": "Advanced Llama3 2 (3B) Grpo Lora",
      "description": "Fine-tune Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:20:14.370077+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "bert-classification",
      "name": "Bert Classification",
      "description": "Fine-tune Bert Classification with Unsloth on NVIDIA GPUs",
      "notebook": "bert_classification.ipynb",
      "path": "bert-classification",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/bert_classification.ipynb",
        "last_synced": "2025-10-21T16:20:13.321760+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "bert_classification.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "codeforces-cot-finetune-for-reasoning-on-codeforces",
      "name": "Codeforces Cot Finetune For Reasoning On Codeforces",
      "description": "Fine-tune Codeforces Cot Finetune For Reasoning On Codeforces with Unsloth on NVIDIA GPUs",
      "notebook": "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
      "path": "codeforces-cot-finetune-for-reasoning-on-codeforces",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
        "last_synced": "2025-10-21T16:20:16.163407+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb"
      ]
    },
    {
      "id": "codegemma-7b",
      "name": "Codegemma (7B) Conversational",
      "description": "Fine-tune Codegemma (7B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "CodeGemma_(7B)-Conversational.ipynb",
      "path": "codegemma-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/CodeGemma_(7B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.176175+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "CodeGemma_(7B)-Conversational.ipynb"
      ]
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b",
      "name": "Deepseek R1 0528 Qwen3 (8B) Grpo",
      "description": "Fine-tune Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:15.015517+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "falcon-h1-0",
      "name": "Falcon H1 (0",
      "description": "Fine-tune Falcon H1 (0 with Unsloth on NVIDIA GPUs",
      "notebook": "Falcon_H1_(0.5B)-Alpaca.ipynb",
      "path": "falcon-h1-0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Falcon_H1_(0.ipynb",
        "last_synced": "2025-10-21T16:20:16.016222+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Falcon_H1_(0.5B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "falcon-h1",
      "name": "Falcon H1 Alpaca",
      "description": "Fine-tune Falcon H1 Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Falcon_H1-Alpaca.ipynb",
      "path": "falcon-h1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Falcon_H1-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:14.009192+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Falcon_H1-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma2-2b",
      "name": "Gemma2 (2B) Alpaca",
      "description": "Fine-tune Gemma2 (2B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma2_(2B)-Alpaca.ipynb",
      "path": "gemma2-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma2_(2B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:14.710423+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Gemma2_(2B)-Alpaca.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma2-9b",
      "name": "Gemma2 (9B) Alpaca",
      "description": "Fine-tune Gemma2 (9B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma2_(9B)-Alpaca.ipynb",
      "path": "gemma2-9b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma2_(9B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:14.131834+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Gemma2_(9B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma3-1b",
      "name": "Gemma3 (1B) Grpo",
      "description": "Fine-tune Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(1B)-GRPO.ipynb",
      "path": "gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:17.544628+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gemma3-270m",
      "name": "Gemma3 (270M)",
      "description": "Fine-tune Gemma3 (270M) with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(270M).ipynb",
      "path": "gemma3-270m",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(270M).ipynb",
        "last_synced": "2025-10-21T16:20:18.936522+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(270M).ipynb"
      ]
    },
    {
      "id": "gemma3-27b",
      "name": "Gemma3 (27B) A100 Conversational",
      "description": "Fine-tune Gemma3 (27B) A100 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(27B)_A100-Conversational.ipynb",
      "path": "gemma3-27b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(27B)_A100-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:15.883471+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(27B)_A100-Conversational.ipynb"
      ]
    },
    {
      "id": "gemma3-4b",
      "name": "Gemma3 (4B)",
      "description": "Fine-tune Gemma3 (4B) with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B).ipynb",
      "path": "gemma3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B).ipynb",
        "last_synced": "2025-10-21T16:20:14.056369+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Gemma3_(4B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma3-4b-vision",
      "name": "Gemma3 (4B) Vision Grpo",
      "description": "Fine-tune Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B)-Vision.ipynb",
      "path": "gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:17.627136+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(4B)-Vision.ipynb",
        "Gemma3_(4B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "gemma3n-2b",
      "name": "Gemma3N (2B) Inference",
      "description": "Fine-tune Gemma3N (2B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(2B)-Inference.ipynb",
      "path": "gemma3n-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(2B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:20:14.197057+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Gemma3N_(2B)-Inference.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma3n-4b-audio",
      "name": "Gemma3N (4B) Audio",
      "description": "Fine-tune Gemma3N (4B) Audio with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Audio.ipynb",
      "path": "gemma3n-4b-audio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Audio.ipynb",
        "last_synced": "2025-10-21T16:20:15.853961+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Audio.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b",
      "name": "Gemma3N (4B) Conversational",
      "description": "Fine-tune Gemma3N (4B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Conversational.ipynb",
      "path": "gemma3n-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.823121+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Conversational.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b-vision",
      "name": "Gemma3N (4B) Vision",
      "description": "Fine-tune Gemma3N (4B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Vision.ipynb",
      "path": "gemma3n-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:20:15.742766+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Vision.ipynb"
      ]
    },
    {
      "id": "gpt-oss-bnb-20b",
      "name": "Gpt Oss Bnb (20B) Inference",
      "description": "Fine-tune Gpt Oss Bnb (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "GPT_OSS_BNB_(20B)-Inference.ipynb",
      "path": "gpt-oss-bnb-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/GPT_OSS_BNB_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:20:18.212341+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "GPT_OSS_BNB_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "gpt-oss-mxfp4-20b",
      "name": "Gpt Oss Mxfp4 (20B) Inference",
      "description": "Fine-tune Gpt Oss Mxfp4 (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "GPT_OSS_MXFP4_(20B)-Inference.ipynb",
      "path": "gpt-oss-mxfp4-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:20:15.156655+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "granite4",
      "name": "Granite4",
      "description": "Fine-tune Granite4 with Unsloth on NVIDIA GPUs",
      "notebook": "Granite4.0.ipynb",
      "path": "granite4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Granite4.ipynb",
        "last_synced": "2025-10-21T16:20:17.221878+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Granite4.0.ipynb"
      ]
    },
    {
      "id": "huggingface course-advanced-llama3-1-3b-grpo-lora",
      "name": "Huggingface Course Advanced Llama3 1 (3B) Grpo Lora",
      "description": "Fine-tune Huggingface Course Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "huggingface course-advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:20:13.297114+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-advanced-llama3-2-3b-grpo-lora",
      "name": "Huggingface Course Advanced Llama3 2 (3B) Grpo Lora",
      "description": "Fine-tune Huggingface Course Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "huggingface course-advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:20:15.315270+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-deepseek-r1-0528-qwen3-8b",
      "name": "Huggingface Course Deepseek R1 0528 Qwen3 (8B) Grpo",
      "description": "Fine-tune Huggingface Course Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "huggingface course-deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:16.413839+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-gemma3-1b",
      "name": "Huggingface Course Gemma3 (1B) Grpo",
      "description": "Fine-tune Huggingface Course Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Gemma3_(1B)-GRPO.ipynb",
      "path": "huggingface course-gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:16.254329+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-gemma3-4b-vision",
      "name": "Huggingface Course Gemma3 (4B) Vision Grpo",
      "description": "Fine-tune Huggingface Course Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
      "path": "huggingface course-gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:13.013957+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-llama3",
      "name": "Huggingface Course Llama3",
      "description": "Fine-tune Huggingface Course Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Llama3.1_(8B)-GRPO.ipynb",
      "path": "huggingface course-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Llama3.ipynb",
        "last_synced": "2025-10-21T16:20:12.248448+00:00"
      },
      "files": [
        "HuggingFace Course-Llama3.1_(8B)-GRPO.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-mistral-v0",
      "name": "Huggingface Course Mistral V0",
      "description": "Fine-tune Huggingface Course Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Mistral_v0.3_(7B)-GRPO.ipynb",
      "path": "huggingface course-mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Mistral_v0.ipynb",
        "last_synced": "2025-10-21T16:20:17.584478+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Mistral_v0.3_(7B)-GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen2",
      "name": "Huggingface Course Qwen2",
      "description": "Fine-tune Huggingface Course Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen2.5_(3B)-GRPO.ipynb",
      "path": "huggingface course-qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen2.ipynb",
        "last_synced": "2025-10-21T16:20:13.850091+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "HuggingFace Course-Qwen2.5_(3B)-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-qwen2-5-7b-vl",
      "name": "Huggingface Course Qwen2 5 7B Vl Grpo",
      "description": "Fine-tune Huggingface Course Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "huggingface course-qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:18.981996+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen3-4b",
      "name": "Huggingface Course Qwen3 (4B) Grpo",
      "description": "Fine-tune Huggingface Course Qwen3 (4B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
      "path": "huggingface course-qwen3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:14.752265+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-advanced-llama3-1-3b-grpo-lora",
      "name": "Kaggle Advanced Llama3 1 (3B) Grpo Lora",
      "description": "Fine-tune Kaggle Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "kaggle-advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:20:16.038706+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "kaggle-advanced-llama3-2-3b-grpo-lora",
      "name": "Kaggle Advanced Llama3 2 (3B) Grpo Lora",
      "description": "Fine-tune Kaggle Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "kaggle-advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:20:16.785191+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "kaggle-bert-classification",
      "name": "Kaggle Bert Classification",
      "description": "Fine-tune Kaggle Bert Classification with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-bert_classification.ipynb",
      "path": "kaggle-bert-classification",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-bert_classification.ipynb",
        "last_synced": "2025-10-21T16:20:13.727087+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-bert_classification.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-codeforces-cot-finetune-for-reasoning-on-codeforces",
      "name": "Kaggle Codeforces Cot Finetune For Reasoning On Codeforces",
      "description": "Fine-tune Kaggle Codeforces Cot Finetune For Reasoning On Codeforces with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
      "path": "kaggle-codeforces-cot-finetune-for-reasoning-on-codeforces",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
        "last_synced": "2025-10-21T16:20:18.492087+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb"
      ]
    },
    {
      "id": "kaggle-codegemma-7b",
      "name": "Kaggle Codegemma (7B) Conversational",
      "description": "Fine-tune Kaggle Codegemma (7B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-CodeGemma_(7B)-Conversational.ipynb",
      "path": "kaggle-codegemma-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-CodeGemma_(7B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:14.519166+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-CodeGemma_(7B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-deepseek-r1-0528-qwen3-8b",
      "name": "Kaggle Deepseek R1 0528 Qwen3 (8B) Grpo",
      "description": "Fine-tune Kaggle Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "kaggle-deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:15.531113+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-falcon-h1-0",
      "name": "Kaggle Falcon H1 (0",
      "description": "Fine-tune Kaggle Falcon H1 (0 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Falcon_H1_(0.5B)-Alpaca.ipynb",
      "path": "kaggle-falcon-h1-0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Falcon_H1_(0.ipynb",
        "last_synced": "2025-10-21T16:20:18.908630+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Falcon_H1_(0.5B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma2-2b",
      "name": "Kaggle Gemma2 (2B) Alpaca",
      "description": "Fine-tune Kaggle Gemma2 (2B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma2_(2B)-Alpaca.ipynb",
      "path": "kaggle-gemma2-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma2_(2B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:17.444084+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma2_(2B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma2-9b",
      "name": "Kaggle Gemma2 (9B) Alpaca",
      "description": "Fine-tune Kaggle Gemma2 (9B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma2_(9B)-Alpaca.ipynb",
      "path": "kaggle-gemma2-9b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma2_(9B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:14.644170+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Gemma2_(9B)-Alpaca.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3-1b",
      "name": "Kaggle Gemma3 (1B) Grpo",
      "description": "Fine-tune Kaggle Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(1B)-GRPO.ipynb",
      "path": "kaggle-gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:15.817400+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3-270m",
      "name": "Kaggle Gemma3 (270M)",
      "description": "Fine-tune Kaggle Gemma3 (270M) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(270M).ipynb",
      "path": "kaggle-gemma3-270m",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(270M).ipynb",
        "last_synced": "2025-10-21T16:20:18.779710+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3_(270M).ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3-27b",
      "name": "Kaggle Gemma3 (27B) A100 Conversational",
      "description": "Fine-tune Kaggle Gemma3 (27B) A100 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(27B)_A100-Conversational.ipynb",
      "path": "kaggle-gemma3-27b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(27B)_A100-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:14.343030+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3_(27B)_A100-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3-4b",
      "name": "Kaggle Gemma3 (4B)",
      "description": "Fine-tune Kaggle Gemma3 (4B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(4B).ipynb",
      "path": "kaggle-gemma3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(4B).ipynb",
        "last_synced": "2025-10-21T16:20:14.305348+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3_(4B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3-4b-vision",
      "name": "Kaggle Gemma3 (4B) Vision Grpo",
      "description": "Fine-tune Kaggle Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(4B)-Vision.ipynb",
      "path": "kaggle-gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:13.750404+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3_(4B)-Vision.ipynb",
        "Kaggle-Gemma3_(4B)-Vision-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3n-2b",
      "name": "Kaggle Gemma3N (2B) Inference",
      "description": "Fine-tune Kaggle Gemma3N (2B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(2B)-Inference.ipynb",
      "path": "kaggle-gemma3n-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(2B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:20:18.191806+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3N_(2B)-Inference.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3n-4b-audio",
      "name": "Kaggle Gemma3N (4B) Audio",
      "description": "Fine-tune Kaggle Gemma3N (4B) Audio with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(4B)-Audio.ipynb",
      "path": "kaggle-gemma3n-4b-audio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(4B)-Audio.ipynb",
        "last_synced": "2025-10-21T16:20:17.250172+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3N_(4B)-Audio.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3n-4b",
      "name": "Kaggle Gemma3N (4B) Conversational",
      "description": "Fine-tune Kaggle Gemma3N (4B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(4B)-Conversational.ipynb",
      "path": "kaggle-gemma3n-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(4B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.122250+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3N_(4B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3n-4b-vision",
      "name": "Kaggle Gemma3N (4B) Vision",
      "description": "Fine-tune Kaggle Gemma3N (4B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(4B)-Vision.ipynb",
      "path": "kaggle-gemma3n-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(4B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:20:14.487399+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3N_(4B)-Vision.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gpt-oss-bnb-20b",
      "name": "Kaggle Gpt Oss Bnb (20B) Inference",
      "description": "Fine-tune Kaggle Gpt Oss Bnb (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-GPT_OSS_BNB_(20B)-Inference.ipynb",
      "path": "kaggle-gpt-oss-bnb-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-GPT_OSS_BNB_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:20:16.821829+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-GPT_OSS_BNB_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "kaggle-gpt-oss-mxfp4-20b",
      "name": "Kaggle Gpt Oss Mxfp4 (20B) Inference",
      "description": "Fine-tune Kaggle Gpt Oss Mxfp4 (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-GPT_OSS_MXFP4_(20B)-Inference.ipynb",
      "path": "kaggle-gpt-oss-mxfp4-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:20:17.113308+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-GPT_OSS_MXFP4_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "kaggle-granite4",
      "name": "Kaggle Granite4",
      "description": "Fine-tune Kaggle Granite4 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Granite4.0.ipynb",
      "path": "kaggle-granite4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Granite4.ipynb",
        "last_synced": "2025-10-21T16:20:15.353358+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-Granite4.0.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-liquid-lfm2-1",
      "name": "Kaggle Liquid Lfm2 (1",
      "description": "Fine-tune Kaggle Liquid Lfm2 (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Liquid_LFM2_(1.2B)-Conversational.ipynb",
      "path": "kaggle-liquid-lfm2-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Liquid_LFM2_(1.ipynb",
        "last_synced": "2025-10-21T16:20:16.644891+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Liquid_LFM2_(1.2B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-llama3",
      "name": "Kaggle Llama3",
      "description": "Fine-tune Kaggle Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3.1_(8B)-Alpaca.ipynb",
      "path": "kaggle-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3.ipynb",
        "last_synced": "2025-10-21T16:20:17.766401+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Llama3.1_(8B)-Alpaca.ipynb",
        "Kaggle-Llama3.2_(11B)-Vision.ipynb",
        "setup.sh",
        "Kaggle-Llama3.1_(8B)-Inference.ipynb",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Llama3.2_(1B)-RAFT.ipynb",
        "Kaggle-Llama3.1_(8B)-GRPO.ipynb",
        "Kaggle-Llama3.3_(70B)_A100-Conversational.ipynb",
        "Kaggle-Llama3.2_(1B_and_3B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-llama3-8b",
      "name": "Kaggle Llama3 (8B) Conversational",
      "description": "Fine-tune Kaggle Llama3 (8B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3_(8B)-Alpaca.ipynb",
      "path": "kaggle-llama3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3_(8B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:15.483007+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-Llama3_(8B)-Alpaca.ipynb",
        "Kaggle-Llama3_(8B)-Conversational.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llama3-8b-ollama",
      "name": "Kaggle Llama3 (8B) Ollama",
      "description": "Fine-tune Kaggle Llama3 (8B) Ollama with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3_(8B)-Ollama.ipynb",
      "path": "kaggle-llama3-8b-ollama",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3_(8B)-Ollama.ipynb",
        "last_synced": "2025-10-21T16:20:12.819160+00:00"
      },
      "files": [
        "Kaggle-Llama3_(8B)-Ollama.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llama3-8b-orpo",
      "name": "Kaggle Llama3 (8B) Orpo",
      "description": "Fine-tune Kaggle Llama3 (8B) Orpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3_(8B)-ORPO.ipynb",
      "path": "kaggle-llama3-8b-orpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3_(8B)-ORPO.ipynb",
        "last_synced": "2025-10-21T16:20:14.966144+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Llama3_(8B)-ORPO.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llasa-tts-1b",
      "name": "Kaggle Llasa Tts (1B)",
      "description": "Fine-tune Kaggle Llasa Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llasa_TTS_(1B).ipynb",
      "path": "kaggle-llasa-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llasa_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:20:15.418656+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-Llasa_TTS_(1B).ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llasa-tts-3b",
      "name": "Kaggle Llasa Tts (3B)",
      "description": "Fine-tune Kaggle Llasa Tts (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llasa_TTS_(3B).ipynb",
      "path": "kaggle-llasa-tts-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llasa_TTS_(3B).ipynb",
        "last_synced": "2025-10-21T16:20:14.941766+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Llasa_TTS_(3B).ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-magistral-24b-reasoning",
      "name": "Kaggle Magistral (24B) Reasoning Conversational",
      "description": "Fine-tune Kaggle Magistral (24B) Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb",
      "path": "kaggle-magistral-24b-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.082966+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-meta-synthetic-data-llama3",
      "name": "Kaggle Meta Synthetic Data Llama3",
      "description": "Fine-tune Kaggle Meta Synthetic Data Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
      "path": "kaggle-meta-synthetic-data-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Meta-Synthetic-Data-Llama3.ipynb",
        "last_synced": "2025-10-21T16:20:18.665246+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).ipynb"
      ]
    },
    {
      "id": "kaggle-meta-synthetic-data-llama3-2-3b",
      "name": "Kaggle Meta Synthetic Data Llama3 2 (3B)",
      "description": "Fine-tune Kaggle Meta Synthetic Data Llama3 2 (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
      "path": "kaggle-meta-synthetic-data-llama3-2-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "last_synced": "2025-10-21T16:20:18.368256+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb"
      ]
    },
    {
      "id": "kaggle-mistral-7b-text-completion",
      "name": "Kaggle Mistral (7B) Text Completion",
      "description": "Fine-tune Kaggle Mistral (7B) Text Completion with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_(7B)-Text_Completion.ipynb",
      "path": "kaggle-mistral-7b-text-completion",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_(7B)-Text_Completion.ipynb",
        "last_synced": "2025-10-21T16:20:12.593036+00:00"
      },
      "files": [
        "Kaggle-Mistral_(7B)-Text_Completion.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-mistral-nemo-12b",
      "name": "Kaggle Mistral Nemo (12B) Alpaca",
      "description": "Fine-tune Kaggle Mistral Nemo (12B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb",
      "path": "kaggle-mistral-nemo-12b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:13.805946+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-mistral-small-22b",
      "name": "Kaggle Mistral Small (22B) Alpaca",
      "description": "Fine-tune Kaggle Mistral Small (22B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_Small_(22B)-Alpaca.ipynb",
      "path": "kaggle-mistral-small-22b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_Small_(22B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:12.778523+00:00"
      },
      "files": [
        "Kaggle-Mistral_Small_(22B)-Alpaca.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-mistral-v0",
      "name": "Kaggle Mistral V0",
      "description": "Fine-tune Kaggle Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_v0.3_(7B)-Conversational.ipynb",
      "path": "kaggle-mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_v0.ipynb",
        "last_synced": "2025-10-21T16:20:19.177227+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Mistral_v0.3_(7B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Mistral_v0.3_(7B)-CPT.ipynb",
        "Kaggle-Mistral_v0.3_(7B)-GRPO.ipynb",
        "Kaggle-Mistral_v0.3_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "kaggle-orpheus-3b-tts",
      "name": "Kaggle Orpheus (3B) Tts",
      "description": "Fine-tune Kaggle Orpheus (3B) Tts with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Orpheus_(3B)-TTS.ipynb",
      "path": "kaggle-orpheus-3b-tts",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Orpheus_(3B)-TTS.ipynb",
        "last_synced": "2025-10-21T16:20:13.583532+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Orpheus_(3B)-TTS.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-oute-tts-1b",
      "name": "Kaggle Oute Tts (1B)",
      "description": "Fine-tune Kaggle Oute Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Oute_TTS_(1B).ipynb",
      "path": "kaggle-oute-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Oute_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:20:17.283585+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Oute_TTS_(1B).ipynb"
      ]
    },
    {
      "id": "kaggle-phi-3",
      "name": "Kaggle Phi 3",
      "description": "Fine-tune Kaggle Phi 3 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_3.5_Mini-Conversational.ipynb",
      "path": "kaggle-phi-3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Phi_3.ipynb",
        "last_synced": "2025-10-21T16:20:17.683141+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_3.5_Mini-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-phi-3-medium",
      "name": "Kaggle Phi 3 Medium Conversational",
      "description": "Fine-tune Kaggle Phi 3 Medium Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_3_Medium-Conversational.ipynb",
      "path": "kaggle-phi-3-medium",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Phi_3_Medium-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.739981+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_3_Medium-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-phi-4",
      "name": "Kaggle Phi 4 Conversational",
      "description": "Fine-tune Kaggle Phi 4 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_4-Conversational.ipynb",
      "path": "kaggle-phi-4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Phi_4-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:17.957245+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_4-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-pixtral-12b-vision",
      "name": "Kaggle Pixtral (12B) Vision",
      "description": "Fine-tune Kaggle Pixtral (12B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Pixtral_(12B)-Vision.ipynb",
      "path": "kaggle-pixtral-12b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Pixtral_(12B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:20:12.201571+00:00"
      },
      "files": [
        "Kaggle-Pixtral_(12B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-qwen2",
      "name": "Kaggle Qwen2",
      "description": "Fine-tune Kaggle Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2.5_VL_(7B)-Vision.ipynb",
      "path": "kaggle-qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2.ipynb",
        "last_synced": "2025-10-21T16:20:18.041868+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Qwen2.5_VL_(7B)-Vision.ipynb",
        "setup.sh",
        "Kaggle-Qwen2.5_(7B)-Alpaca.ipynb",
        "README.md",
        "Kaggle-Qwen2.5_(3B)-GRPO.ipynb",
        "docker-compose.yml",
        "Kaggle-Qwen2.5_Coder_(14B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen2-7b",
      "name": "Kaggle Qwen2 (7B) Alpaca",
      "description": "Fine-tune Kaggle Qwen2 (7B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2_(7B)-Alpaca.ipynb",
      "path": "kaggle-qwen2-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_(7B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:14.096271+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Qwen2_(7B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-qwen2-5-7b-vl",
      "name": "Kaggle Qwen2 5 7B Vl Grpo",
      "description": "Fine-tune Kaggle Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "kaggle-qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:17.483678+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen2_5_7B_VL_GRPO.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen2-vl-7b-vision",
      "name": "Kaggle Qwen2 Vl (7B) Vision",
      "description": "Fine-tune Kaggle Qwen2 Vl (7B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2_VL_(7B)-Vision.ipynb",
      "path": "kaggle-qwen2-vl-7b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_VL_(7B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:20:15.941373+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen2_VL_(7B)-Vision.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen2.5-coder-1",
      "name": "Kaggle Qwen2.5 Coder (1",
      "description": "Fine-tune Kaggle Qwen2.5 Coder (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
      "path": "kaggle-qwen2.5-coder-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2.5_Coder_(1.ipynb",
        "last_synced": "2025-10-21T16:20:16.995316+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen3-32b-a100-reasoning",
      "name": "Kaggle Qwen3 (32B) A100 Reasoning Conversational",
      "description": "Fine-tune Kaggle Qwen3 (32B) A100 Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
      "path": "kaggle-qwen3-32b-a100-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:16.294342+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen3-4b",
      "name": "Kaggle Qwen3 (4B) Grpo",
      "description": "Fine-tune Kaggle Qwen3 (4B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(4B)-GRPO.ipynb",
      "path": "kaggle-qwen3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(4B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:18.604710+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(4B)-GRPO.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen3-4b-instruct",
      "name": "Kaggle Qwen3 (4B) Instruct",
      "description": "Fine-tune Kaggle Qwen3 (4B) Instruct with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(4B)-Instruct.ipynb",
      "path": "kaggle-qwen3-4b-instruct",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(4B)-Instruct.ipynb",
        "last_synced": "2025-10-21T16:20:12.862262+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Qwen3_(4B)-Instruct.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-qwen3-4b-thinking",
      "name": "Kaggle Qwen3 (4B) Thinking",
      "description": "Fine-tune Kaggle Qwen3 (4B) Thinking with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(4B)-Thinking.ipynb",
      "path": "kaggle-qwen3-4b-thinking",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(4B)-Thinking.ipynb",
        "last_synced": "2025-10-21T16:20:18.696782+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(4B)-Thinking.ipynb"
      ]
    },
    {
      "id": "kaggle-spark-tts-0-5b",
      "name": "Kaggle Spark Tts (0 5B)",
      "description": "Fine-tune Kaggle Spark Tts (0 5B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Spark_TTS_(0_5B).ipynb",
      "path": "kaggle-spark-tts-0-5b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Spark_TTS_(0_5B).ipynb",
        "last_synced": "2025-10-21T16:20:17.896152+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Spark_TTS_(0_5B).ipynb"
      ]
    },
    {
      "id": "kaggle-tinyllama-1",
      "name": "Kaggle Tinyllama (1",
      "description": "Fine-tune Kaggle Tinyllama (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-TinyLlama_(1.1B)-Alpaca.ipynb",
      "path": "kaggle-tinyllama-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-TinyLlama_(1.ipynb",
        "last_synced": "2025-10-21T16:20:14.409116+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-TinyLlama_(1.1B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-unsloth-studio",
      "name": "Kaggle Unsloth Studio",
      "description": "Fine-tune Kaggle Unsloth Studio with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Unsloth_Studio.ipynb",
      "path": "kaggle-unsloth-studio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Unsloth_Studio.ipynb",
        "last_synced": "2025-10-21T16:20:16.143979+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Unsloth_Studio.ipynb"
      ]
    },
    {
      "id": "kaggle-whisper",
      "name": "Kaggle Whisper",
      "description": "Fine-tune Kaggle Whisper with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Whisper.ipynb",
      "path": "kaggle-whisper",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Whisper.ipynb",
        "last_synced": "2025-10-21T16:20:16.896937+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Whisper.ipynb"
      ]
    },
    {
      "id": "kaggle-zephyr-7b-dpo",
      "name": "Kaggle Zephyr (7B) Dpo",
      "description": "Fine-tune Kaggle Zephyr (7B) Dpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Zephyr_(7B)-DPO.ipynb",
      "path": "kaggle-zephyr-7b-dpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Zephyr_(7B)-DPO.ipynb",
        "last_synced": "2025-10-21T16:20:17.719230+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Zephyr_(7B)-DPO.ipynb"
      ]
    },
    {
      "id": "liquid-lfm2-1",
      "name": "Liquid Lfm2 (1",
      "description": "Fine-tune Liquid Lfm2 (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Liquid_LFM2_(1.2B)-Conversational.ipynb",
      "path": "liquid-lfm2-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Liquid_LFM2_(1.ipynb",
        "last_synced": "2025-10-21T16:20:12.974800+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Liquid_LFM2_(1.2B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "liquid-lfm2",
      "name": "Liquid Lfm2 Conversational",
      "description": "Fine-tune Liquid Lfm2 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Liquid_LFM2-Conversational.ipynb",
      "path": "liquid-lfm2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Liquid_LFM2-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.236943+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Liquid_LFM2-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3",
      "name": "Llama3",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.2_(11B)-Vision.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-21T16:20:17.812746+00:00"
      },
      "files": [
        "Llama3.2_(11B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Llama3.2_(1B_and_3B)-Conversational.ipynb",
        "README.md",
        "Llama3.1_(8B)-GRPO.ipynb",
        "docker-compose.yml",
        "Llama3.2_(1B)-RAFT.ipynb",
        "Llama3.1_(8B)-Alpaca.ipynb",
        "Llama3.3_(70B)_A100-Conversational.ipynb",
        "Llama3.1_(8B)-Inference.ipynb"
      ]
    },
    {
      "id": "llama3-8b",
      "name": "Llama3 (8B) Conversational",
      "description": "Fine-tune Llama3 (8B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Alpaca.ipynb",
      "path": "llama3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.540632+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3_(8B)-Alpaca.ipynb",
        "Llama3_(8B)-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3-8b-ollama",
      "name": "Llama3 (8B) Ollama",
      "description": "Fine-tune Llama3 (8B) Ollama with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Ollama.ipynb",
      "path": "llama3-8b-ollama",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb",
        "last_synced": "2025-10-21T16:20:13.542927+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Llama3_(8B)-Ollama.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "llama3-8b-orpo",
      "name": "Llama3 (8B) Orpo",
      "description": "Fine-tune Llama3 (8B) Orpo with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-ORPO.ipynb",
      "path": "llama3-8b-orpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-ORPO.ipynb",
        "last_synced": "2025-10-21T16:20:12.904193+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Llama3_(8B)-ORPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "llasa-tts-1b",
      "name": "Llasa Tts (1B)",
      "description": "Fine-tune Llasa Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Llasa_TTS_(1B).ipynb",
      "path": "llasa-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llasa_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:20:15.286108+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Llasa_TTS_(1B).ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "llasa-tts-3b",
      "name": "Llasa Tts (3B)",
      "description": "Fine-tune Llasa Tts (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Llasa_TTS_(3B).ipynb",
      "path": "llasa-tts-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llasa_TTS_(3B).ipynb",
        "last_synced": "2025-10-21T16:20:12.346561+00:00"
      },
      "files": [
        "Llasa_TTS_(3B).ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "magistral-24b-reasoning",
      "name": "Magistral (24B) Reasoning Conversational",
      "description": "Fine-tune Magistral (24B) Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Magistral_(24B)-Reasoning-Conversational.ipynb",
      "path": "magistral-24b-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Magistral_(24B)-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:12.936961+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Magistral_(24B)-Reasoning-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "meta-synthetic-data-llama3",
      "name": "Meta Synthetic Data Llama3",
      "description": "Fine-tune Meta Synthetic Data Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
      "path": "meta-synthetic-data-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Meta-Synthetic-Data-Llama3.ipynb",
        "last_synced": "2025-10-21T16:20:15.689835+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "meta-synthetic-data-llama3-2-3b",
      "name": "Meta Synthetic Data Llama3 2 (3B)",
      "description": "Fine-tune Meta Synthetic Data Llama3 2 (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
      "path": "meta-synthetic-data-llama3-2-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "last_synced": "2025-10-21T16:20:13.375367+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "mistral-7b-text-completion",
      "name": "Mistral (7B) Text Completion",
      "description": "Fine-tune Mistral (7B) Text Completion with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_(7B)-Text_Completion.ipynb",
      "path": "mistral-7b-text-completion",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb",
        "last_synced": "2025-10-21T16:20:17.077023+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_(7B)-Text_Completion.ipynb"
      ]
    },
    {
      "id": "mistral-nemo-12b",
      "name": "Mistral Nemo (12B) Alpaca",
      "description": "Fine-tune Mistral Nemo (12B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_Nemo_(12B)-Alpaca.ipynb",
      "path": "mistral-nemo-12b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_Nemo_(12B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:14.572319+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Mistral_Nemo_(12B)-Alpaca.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "mistral-small-22b",
      "name": "Mistral Small (22B) Alpaca",
      "description": "Fine-tune Mistral Small (22B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_Small_(22B)-Alpaca.ipynb",
      "path": "mistral-small-22b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_Small_(22B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:17.919379+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_Small_(22B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "mistral-v0",
      "name": "Mistral V0",
      "description": "Fine-tune Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_v0.3_(7B)-CPT.ipynb",
      "path": "mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_v0.ipynb",
        "last_synced": "2025-10-21T16:20:18.271779+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Mistral_v0.3_(7B)-CPT.ipynb",
        "Mistral_v0.3_(7B)-GRPO.ipynb",
        "Mistral_v0.3_(7B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_v0.3_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "orpheus-3b-tts",
      "name": "Orpheus (3B) Tts",
      "description": "Fine-tune Orpheus (3B) Tts with Unsloth on NVIDIA GPUs",
      "notebook": "Orpheus_(3B)-TTS.ipynb",
      "path": "orpheus-3b-tts",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Orpheus_(3B)-TTS.ipynb",
        "last_synced": "2025-10-21T16:20:15.129525+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Orpheus_(3B)-TTS.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "oute-tts-1b",
      "name": "Oute Tts (1B)",
      "description": "Fine-tune Oute Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Oute_TTS_(1B).ipynb",
      "path": "oute-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Oute_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:20:13.343783+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Oute_TTS_(1B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "phi-3",
      "name": "Phi 3",
      "description": "Fine-tune Phi 3 with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_3.5_Mini-Conversational.ipynb",
      "path": "phi-3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi_3.ipynb",
        "last_synced": "2025-10-21T16:20:18.401563+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_3.5_Mini-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-3-medium",
      "name": "Phi 3 Medium Conversational",
      "description": "Fine-tune Phi 3 Medium Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_3_Medium-Conversational.ipynb",
      "path": "phi-3-medium",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi_3_Medium-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:18.328195+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_3_Medium-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-4-14b-fine-tuning",
      "name": "Phi-4 (14B)",
      "description": "Fine-tune Phi-4 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_4-Conversational.ipynb",
      "path": "phi-4-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi-4_(14B).ipynb",
        "last_synced": "2025-10-21T16:20:18.571697+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_4-Conversational.ipynb",
        "Kaggle-Phi_4_(14B)-GRPO.ipynb",
        "Phi_4_(14B)-GRPO.ipynb",
        "HuggingFace Course-Phi_4_(14B)-GRPO.ipynb"
      ]
    },
    {
      "id": "pixtral-12b-vision",
      "name": "Pixtral (12B) Vision",
      "description": "Fine-tune Pixtral (12B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Pixtral_(12B)-Vision.ipynb",
      "path": "pixtral-12b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:20:14.443933+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Pixtral_(12B)-Vision.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen2",
      "name": "Qwen2",
      "description": "Fine-tune Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_VL_(7B)-Vision.ipynb",
      "path": "qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.ipynb",
        "last_synced": "2025-10-21T16:20:17.178700+00:00"
      },
      "files": [
        "Qwen2.5_VL_(7B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "Qwen2.5_(7B)-Alpaca.ipynb",
        "setup.sh",
        "Qwen2.5_(3B)-GRPO.ipynb",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_Coder_(14B)-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen2-7b",
      "name": "Qwen2 (7B) Alpaca",
      "description": "Fine-tune Qwen2 (7B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_(7B)-Alpaca.ipynb",
      "path": "qwen2-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_(7B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:20:15.904644+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "qwen2-5-7b-vl",
      "name": "Qwen2 5 7B Vl Grpo",
      "description": "Fine-tune Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-21T16:20:13.236534+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Qwen2_5_7B_VL_GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen2-vl-7b-vision",
      "name": "Qwen2 Vl (7B) Vision",
      "description": "Fine-tune Qwen2 Vl (7B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_VL_(7B)-Vision.ipynb",
      "path": "qwen2-vl-7b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:20:12.550255+00:00"
      },
      "files": [
        "Qwen2_VL_(7B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen2.5-coder-1",
      "name": "Qwen2.5 Coder (1",
      "description": "Fine-tune Qwen2.5 Coder (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
      "path": "qwen2.5-coder-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_(1.ipynb",
        "last_synced": "2025-10-21T16:20:12.738779+00:00"
      },
      "files": [
        "Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning",
      "name": "Qwen3 (14B)",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(14B)-Alpaca.ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-21T16:20:19.063349+00:00"
      },
      "files": [
        "Qwen3_(14B)-Alpaca.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Qwen3_(14B)-Alpaca.ipynb",
        "README.md",
        "Kaggle-Qwen3_(14B).ipynb",
        "docker-compose.yml",
        "Kaggle-Qwen3_(14B)-Reasoning-Conversational.ipynb",
        "Qwen3_(14B).ipynb",
        "Qwen3_(14B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-32b-a100-reasoning",
      "name": "Qwen3 (32B) A100 Reasoning Conversational",
      "description": "Fine-tune Qwen3 (32B) A100 Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
      "path": "qwen3-32b-a100-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:20:16.730575+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(32B)_A100-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-grpo-rl",
      "name": "Qwen3 (4B) GRPO",
      "description": "Fine-tune Qwen3 (4B) GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-GRPO.ipynb",
      "path": "qwen3-4b-grpo-rl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reinforcement-learning",
        "grpo",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)_grpo.ipynb",
        "last_synced": "2025-10-21T16:20:19.117220+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-instruct",
      "name": "Qwen3 (4B) Instruct",
      "description": "Fine-tune Qwen3 (4B) Instruct with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-Instruct.ipynb",
      "path": "qwen3-4b-instruct",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-Instruct.ipynb",
        "last_synced": "2025-10-21T16:20:17.999111+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-Instruct.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-thinking",
      "name": "Qwen3 (4B) Thinking",
      "description": "Fine-tune Qwen3 (4B) Thinking with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-Thinking.ipynb",
      "path": "qwen3-4b-thinking",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-Thinking.ipynb",
        "last_synced": "2025-10-21T16:20:16.345257+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-Thinking.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision",
      "name": "Qwen3-VL (8B)",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-21T16:20:19.038363+00:00"
      },
      "files": [
        "HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
        "Kaggle-Qwen3_VL_(8B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "Qwen3_VL_(8B)-Vision-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
        "Qwen3_VL_(8B)-Vision.ipynb"
      ]
    },
    {
      "id": "sesame-csm-1b-tts",
      "name": "Sesame-CSM (1B)",
      "description": "Fine-tune Sesame-CSM (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Sesame_CSM_(1B)-TTS.ipynb",
      "path": "sesame-csm-1b-tts",
      "gpu": {
        "tier": "T4",
        "min_vram_gb": 12,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "text-to-speech",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Sesame-CSM_(1B).ipynb",
        "last_synced": "2025-10-21T16:20:17.142456+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Sesame_CSM_(1B)-TTS.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Sesame_CSM_(1B)-TTS.ipynb"
      ]
    },
    {
      "id": "spark-tts-0-5b",
      "name": "Spark Tts (0 5B)",
      "description": "Fine-tune Spark Tts (0 5B) with Unsloth on NVIDIA GPUs",
      "notebook": "Spark_TTS_(0_5B).ipynb",
      "path": "spark-tts-0-5b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Spark_TTS_(0_5B).ipynb",
        "last_synced": "2025-10-21T16:20:15.718212+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Spark_TTS_(0_5B).ipynb"
      ]
    },
    {
      "id": "synthetic-data-hackathon",
      "name": "Synthetic Data Hackathon",
      "description": "Fine-tune Synthetic Data Hackathon with Unsloth on NVIDIA GPUs",
      "notebook": "Synthetic_Data_Hackathon.ipynb",
      "path": "synthetic-data-hackathon",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Synthetic_Data_Hackathon.ipynb",
        "last_synced": "2025-10-21T16:20:17.797578+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Synthetic_Data_Hackathon.ipynb"
      ]
    },
    {
      "id": "tinyllama-1",
      "name": "Tinyllama (1",
      "description": "Fine-tune Tinyllama (1 with Unsloth on NVIDIA GPUs",
      "notebook": "TinyLlama_(1.1B)-Alpaca.ipynb",
      "path": "tinyllama-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/TinyLlama_(1.ipynb",
        "last_synced": "2025-10-21T16:20:12.408623+00:00"
      },
      "files": [
        "TinyLlama_(1.1B)-Alpaca.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "unsloth-studio",
      "name": "Unsloth Studio",
      "description": "Fine-tune Unsloth Studio with Unsloth on NVIDIA GPUs",
      "notebook": "Unsloth_Studio.ipynb",
      "path": "unsloth-studio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb",
        "last_synced": "2025-10-21T16:20:12.662194+00:00"
      },
      "files": [
        "Unsloth_Studio.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "whisper-large-v3-stt",
      "name": "Whisper Large V3",
      "description": "Fine-tune Whisper Large V3 with Unsloth on NVIDIA GPUs",
      "notebook": "Whisper.ipynb",
      "path": "whisper-large-v3-stt",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "speech-to-text",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Whisper_Large_V3.ipynb",
        "last_synced": "2025-10-21T16:20:13.188593+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Whisper.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "zephyr-7b-dpo",
      "name": "Zephyr (7B) Dpo",
      "description": "Fine-tune Zephyr (7B) Dpo with Unsloth on NVIDIA GPUs",
      "notebook": "Zephyr_(7B)-DPO.ipynb",
      "path": "zephyr-7b-dpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Zephyr_(7B)-DPO.ipynb",
        "last_synced": "2025-10-21T16:20:17.365309+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Zephyr_(7B)-DPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-120b-fine-tuning",
      "name": "gpt-oss-120b",
      "description": "Fine-tune gpt-oss-120b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt-oss-(120B)_A100-Fine-tuning.ipynb",
      "path": "gpt-oss-120b-fine-tuning",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 80,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-120b.ipynb",
        "last_synced": "2025-10-21T16:20:18.437539+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "gpt-oss-(120B)_A100-Fine-tuning.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(120B)_A100-Fine-tuning.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning",
      "name": "gpt-oss-20b",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-21T16:20:19.211978+00:00"
      },
      "files": [
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark.ipynb",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game.ipynb",
        "Kaggle-gpt-oss-(20B)_A100-GRPO.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "gpt-oss-(20B)_A100-GRPO.ipynb",
        "gpt-oss-(20B)-GRPO.ipynb",
        "HuggingFace Course-gpt-oss-(20B)_A100-GRPO.ipynb",
        "setup.sh",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_BF16.ipynb",
        "README.md",
        "gpt-oss-(20B)-Fine-tuning.ipynb",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(20B)-GRPO.ipynb",
        "Kaggle-gpt-oss-(20B)-Fine-tuning.ipynb",
        "HuggingFace Course-gpt-oss-(20B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-grpo-rl",
      "name": "gpt-oss-20b-GRPO",
      "description": "Fine-tune gpt-oss-20b-GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_GRPO_BF16.ipynb",
      "path": "gpt-oss-20b-grpo-rl",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 40,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "reinforcement-learning",
        "grpo"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b-grpo.ipynb",
        "last_synced": "2025-10-21T16:20:16.944231+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt_oss_(20B)_GRPO_BF16.ipynb"
      ]
    }
  ]
}