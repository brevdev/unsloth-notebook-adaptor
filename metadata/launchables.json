{
  "version": "1.0.0",
  "generated_at": "2025-10-21T16:25:59.099978+00:00",
  "total_launchables": 129,
  "launchables": [
    {
      "id": "advanced-llama3-1-3b-grpo-lora",
      "name": "Advanced Llama3 1 (3B) Grpo Lora",
      "description": "Fine-tune Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:25:52.495367+00:00"
      },
      "files": [
        "Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "advanced-llama3-2-3b-grpo-lora",
      "name": "Advanced Llama3 2 (3B) Grpo Lora",
      "description": "Fine-tune Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:25:54.295336+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "bert-classification",
      "name": "Bert Classification",
      "description": "Fine-tune Bert Classification with Unsloth on NVIDIA GPUs",
      "notebook": "bert_classification.ipynb",
      "path": "bert-classification",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/bert_classification.ipynb",
        "last_synced": "2025-10-21T16:25:53.290415+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "bert_classification.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "codeforces-cot-finetune-for-reasoning-on-codeforces",
      "name": "Codeforces Cot Finetune For Reasoning On Codeforces",
      "description": "Fine-tune Codeforces Cot Finetune For Reasoning On Codeforces with Unsloth on NVIDIA GPUs",
      "notebook": "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
      "path": "codeforces-cot-finetune-for-reasoning-on-codeforces",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
        "last_synced": "2025-10-21T16:25:56.019365+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb"
      ]
    },
    {
      "id": "codegemma-7b",
      "name": "Codegemma (7B) Conversational",
      "description": "Fine-tune Codegemma (7B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "CodeGemma_(7B)-Conversational.ipynb",
      "path": "codegemma-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/CodeGemma_(7B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:57.936421+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "CodeGemma_(7B)-Conversational.ipynb"
      ]
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b",
      "name": "Deepseek R1 0528 Qwen3 (8B) Grpo",
      "description": "Fine-tune Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:54.919847+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "falcon-h1-0",
      "name": "Falcon H1 (0",
      "description": "Fine-tune Falcon H1 (0 with Unsloth on NVIDIA GPUs",
      "notebook": "Falcon_H1_(0.5B)-Alpaca.ipynb",
      "path": "falcon-h1-0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Falcon_H1_(0.ipynb",
        "last_synced": "2025-10-21T16:25:55.879621+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Falcon_H1_(0.5B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "falcon-h1",
      "name": "Falcon H1 Alpaca",
      "description": "Fine-tune Falcon H1 Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Falcon_H1-Alpaca.ipynb",
      "path": "falcon-h1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Falcon_H1-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:53.947795+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Falcon_H1-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma2-2b",
      "name": "Gemma2 (2B) Alpaca",
      "description": "Fine-tune Gemma2 (2B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma2_(2B)-Alpaca.ipynb",
      "path": "gemma2-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma2_(2B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:54.624849+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Gemma2_(2B)-Alpaca.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma2-9b",
      "name": "Gemma2 (9B) Alpaca",
      "description": "Fine-tune Gemma2 (9B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma2_(9B)-Alpaca.ipynb",
      "path": "gemma2-9b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma2_(9B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:54.066855+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Gemma2_(9B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma3-1b",
      "name": "Gemma3 (1B) Grpo",
      "description": "Fine-tune Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(1B)-GRPO.ipynb",
      "path": "gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:57.326434+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gemma3-270m",
      "name": "Gemma3 (270M)",
      "description": "Fine-tune Gemma3 (270M) with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(270M).ipynb",
      "path": "gemma3-270m",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(270M).ipynb",
        "last_synced": "2025-10-21T16:25:58.692512+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(270M).ipynb"
      ]
    },
    {
      "id": "gemma3-27b",
      "name": "Gemma3 (27B) A100 Conversational",
      "description": "Fine-tune Gemma3 (27B) A100 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(27B)_A100-Conversational.ipynb",
      "path": "gemma3-27b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(27B)_A100-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:55.755427+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(27B)_A100-Conversational.ipynb"
      ]
    },
    {
      "id": "gemma3-4b",
      "name": "Gemma3 (4B)",
      "description": "Fine-tune Gemma3 (4B) with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B).ipynb",
      "path": "gemma3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B).ipynb",
        "last_synced": "2025-10-21T16:25:53.993631+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Gemma3_(4B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma3-4b-vision",
      "name": "Gemma3 (4B) Vision Grpo",
      "description": "Fine-tune Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3_(4B)-Vision.ipynb",
      "path": "gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:57.404509+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3_(4B)-Vision.ipynb",
        "Gemma3_(4B)-Vision-GRPO.ipynb"
      ]
    },
    {
      "id": "gemma3n-2b",
      "name": "Gemma3N (2B) Inference",
      "description": "Fine-tune Gemma3N (2B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(2B)-Inference.ipynb",
      "path": "gemma3n-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(2B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:25:54.129356+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Gemma3N_(2B)-Inference.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "gemma3n-4b-audio",
      "name": "Gemma3N (4B) Audio",
      "description": "Fine-tune Gemma3N (4B) Audio with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Audio.ipynb",
      "path": "gemma3n-4b-audio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Audio.ipynb",
        "last_synced": "2025-10-21T16:25:55.726503+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Audio.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b",
      "name": "Gemma3N (4B) Conversational",
      "description": "Fine-tune Gemma3N (4B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Conversational.ipynb",
      "path": "gemma3n-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:58.579756+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Conversational.ipynb"
      ]
    },
    {
      "id": "gemma3n-4b-vision",
      "name": "Gemma3N (4B) Vision",
      "description": "Fine-tune Gemma3N (4B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Gemma3N_(4B)-Vision.ipynb",
      "path": "gemma3n-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:25:55.617469+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Gemma3N_(4B)-Vision.ipynb"
      ]
    },
    {
      "id": "gpt-oss-bnb-20b",
      "name": "Gpt Oss Bnb (20B) Inference",
      "description": "Fine-tune Gpt Oss Bnb (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "GPT_OSS_BNB_(20B)-Inference.ipynb",
      "path": "gpt-oss-bnb-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/GPT_OSS_BNB_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:25:57.972353+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "GPT_OSS_BNB_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "gpt-oss-mxfp4-20b",
      "name": "Gpt Oss Mxfp4 (20B) Inference",
      "description": "Fine-tune Gpt Oss Mxfp4 (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "GPT_OSS_MXFP4_(20B)-Inference.ipynb",
      "path": "gpt-oss-mxfp4-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:25:55.056145+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "granite4",
      "name": "Granite4",
      "description": "Fine-tune Granite4 with Unsloth on NVIDIA GPUs",
      "notebook": "Granite4.0.ipynb",
      "path": "granite4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Granite4.ipynb",
        "last_synced": "2025-10-21T16:25:57.018575+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Granite4.0.ipynb"
      ]
    },
    {
      "id": "huggingface course-advanced-llama3-1-3b-grpo-lora",
      "name": "Huggingface Course Advanced Llama3 1 (3B) Grpo Lora",
      "description": "Fine-tune Huggingface Course Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "huggingface course-advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:25:53.267166+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "HuggingFace Course-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-advanced-llama3-2-3b-grpo-lora",
      "name": "Huggingface Course Advanced Llama3 2 (3B) Grpo Lora",
      "description": "Fine-tune Huggingface Course Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "huggingface course-advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:25:55.207902+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "HuggingFace Course-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-deepseek-r1-0528-qwen3-8b",
      "name": "Huggingface Course Deepseek R1 0528 Qwen3 (8B) Grpo",
      "description": "Fine-tune Huggingface Course Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "huggingface course-deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:56.258090+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-gemma3-1b",
      "name": "Huggingface Course Gemma3 (1B) Grpo",
      "description": "Fine-tune Huggingface Course Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Gemma3_(1B)-GRPO.ipynb",
      "path": "huggingface course-gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:56.106344+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-gemma3-4b-vision",
      "name": "Huggingface Course Gemma3 (4B) Vision Grpo",
      "description": "Fine-tune Huggingface Course Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
      "path": "huggingface course-gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:52.983280+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-llama3",
      "name": "Huggingface Course Llama3",
      "description": "Fine-tune Huggingface Course Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Llama3.1_(8B)-GRPO.ipynb",
      "path": "huggingface course-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Llama3.ipynb",
        "last_synced": "2025-10-21T16:25:52.215335+00:00"
      },
      "files": [
        "HuggingFace Course-Llama3.1_(8B)-GRPO.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-mistral-v0",
      "name": "Huggingface Course Mistral V0",
      "description": "Fine-tune Huggingface Course Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Mistral_v0.3_(7B)-GRPO.ipynb",
      "path": "huggingface course-mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Mistral_v0.ipynb",
        "last_synced": "2025-10-21T16:25:57.363907+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Mistral_v0.3_(7B)-GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen2",
      "name": "Huggingface Course Qwen2",
      "description": "Fine-tune Huggingface Course Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen2.5_(3B)-GRPO.ipynb",
      "path": "huggingface course-qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen2.ipynb",
        "last_synced": "2025-10-21T16:25:53.791079+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "HuggingFace Course-Qwen2.5_(3B)-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "huggingface course-qwen2-5-7b-vl",
      "name": "Huggingface Course Qwen2 5 7B Vl Grpo",
      "description": "Fine-tune Huggingface Course Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "huggingface course-qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:58.737747+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb"
      ]
    },
    {
      "id": "huggingface course-qwen3-4b",
      "name": "Huggingface Course Qwen3 (4B) Grpo",
      "description": "Fine-tune Huggingface Course Qwen3 (4B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
      "path": "huggingface course-qwen3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:54.665959+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "HuggingFace Course-Qwen3_(4B)-GRPO.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-advanced-llama3-1-3b-grpo-lora",
      "name": "Kaggle Advanced Llama3 1 (3B) Grpo Lora",
      "description": "Fine-tune Kaggle Advanced Llama3 1 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
      "path": "kaggle-advanced-llama3-1-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:25:55.900058+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "kaggle-advanced-llama3-2-3b-grpo-lora",
      "name": "Kaggle Advanced Llama3 2 (3B) Grpo Lora",
      "description": "Fine-tune Kaggle Advanced Llama3 2 (3B) Grpo Lora with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
      "path": "kaggle-advanced-llama3-2-3b-grpo-lora",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb",
        "last_synced": "2025-10-21T16:25:56.608592+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb"
      ]
    },
    {
      "id": "kaggle-bert-classification",
      "name": "Kaggle Bert Classification",
      "description": "Fine-tune Kaggle Bert Classification with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-bert_classification.ipynb",
      "path": "kaggle-bert-classification",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-bert_classification.ipynb",
        "last_synced": "2025-10-21T16:25:53.676342+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-bert_classification.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-codeforces-cot-finetune-for-reasoning-on-codeforces",
      "name": "Kaggle Codeforces Cot Finetune For Reasoning On Codeforces",
      "description": "Fine-tune Kaggle Codeforces Cot Finetune For Reasoning On Codeforces with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
      "path": "kaggle-codeforces-cot-finetune-for-reasoning-on-codeforces",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb",
        "last_synced": "2025-10-21T16:25:58.252047+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb"
      ]
    },
    {
      "id": "kaggle-codegemma-7b",
      "name": "Kaggle Codegemma (7B) Conversational",
      "description": "Fine-tune Kaggle Codegemma (7B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-CodeGemma_(7B)-Conversational.ipynb",
      "path": "kaggle-codegemma-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-CodeGemma_(7B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:54.439316+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-CodeGemma_(7B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-deepseek-r1-0528-qwen3-8b",
      "name": "Kaggle Deepseek R1 0528 Qwen3 (8B) Grpo",
      "description": "Fine-tune Kaggle Deepseek R1 0528 Qwen3 (8B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
      "path": "kaggle-deepseek-r1-0528-qwen3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:55.413670+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-falcon-h1-0",
      "name": "Kaggle Falcon H1 (0",
      "description": "Fine-tune Kaggle Falcon H1 (0 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Falcon_H1_(0.5B)-Alpaca.ipynb",
      "path": "kaggle-falcon-h1-0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Falcon_H1_(0.ipynb",
        "last_synced": "2025-10-21T16:25:58.664633+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Falcon_H1_(0.5B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma2-2b",
      "name": "Kaggle Gemma2 (2B) Alpaca",
      "description": "Fine-tune Kaggle Gemma2 (2B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma2_(2B)-Alpaca.ipynb",
      "path": "kaggle-gemma2-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma2_(2B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:57.232079+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma2_(2B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma2-9b",
      "name": "Kaggle Gemma2 (9B) Alpaca",
      "description": "Fine-tune Kaggle Gemma2 (9B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma2_(9B)-Alpaca.ipynb",
      "path": "kaggle-gemma2-9b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma2_(9B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:54.561008+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Gemma2_(9B)-Alpaca.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3-1b",
      "name": "Kaggle Gemma3 (1B) Grpo",
      "description": "Fine-tune Kaggle Gemma3 (1B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(1B)-GRPO.ipynb",
      "path": "kaggle-gemma3-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(1B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:55.691315+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3_(1B)-GRPO.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3-270m",
      "name": "Kaggle Gemma3 (270M)",
      "description": "Fine-tune Kaggle Gemma3 (270M) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(270M).ipynb",
      "path": "kaggle-gemma3-270m",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(270M).ipynb",
        "last_synced": "2025-10-21T16:25:58.537043+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3_(270M).ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3-27b",
      "name": "Kaggle Gemma3 (27B) A100 Conversational",
      "description": "Fine-tune Kaggle Gemma3 (27B) A100 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(27B)_A100-Conversational.ipynb",
      "path": "kaggle-gemma3-27b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(27B)_A100-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:54.269383+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3_(27B)_A100-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3-4b",
      "name": "Kaggle Gemma3 (4B)",
      "description": "Fine-tune Kaggle Gemma3 (4B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(4B).ipynb",
      "path": "kaggle-gemma3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(4B).ipynb",
        "last_synced": "2025-10-21T16:25:54.233425+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3_(4B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3-4b-vision",
      "name": "Kaggle Gemma3 (4B) Vision Grpo",
      "description": "Fine-tune Kaggle Gemma3 (4B) Vision Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3_(4B)-Vision.ipynb",
      "path": "kaggle-gemma3-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3_(4B)-Vision-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:53.698275+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3_(4B)-Vision.ipynb",
        "Kaggle-Gemma3_(4B)-Vision-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gemma3n-2b",
      "name": "Kaggle Gemma3N (2B) Inference",
      "description": "Fine-tune Kaggle Gemma3N (2B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(2B)-Inference.ipynb",
      "path": "kaggle-gemma3n-2b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(2B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:25:57.951749+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3N_(2B)-Inference.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3n-4b-audio",
      "name": "Kaggle Gemma3N (4B) Audio",
      "description": "Fine-tune Kaggle Gemma3N (4B) Audio with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(4B)-Audio.ipynb",
      "path": "kaggle-gemma3n-4b-audio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(4B)-Audio.ipynb",
        "last_synced": "2025-10-21T16:25:57.045974+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3N_(4B)-Audio.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3n-4b",
      "name": "Kaggle Gemma3N (4B) Conversational",
      "description": "Fine-tune Kaggle Gemma3N (4B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(4B)-Conversational.ipynb",
      "path": "kaggle-gemma3n-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(4B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:57.892891+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Gemma3N_(4B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-gemma3n-4b-vision",
      "name": "Kaggle Gemma3N (4B) Vision",
      "description": "Fine-tune Kaggle Gemma3N (4B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Gemma3N_(4B)-Vision.ipynb",
      "path": "kaggle-gemma3n-4b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(4B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:25:54.408732+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Gemma3N_(4B)-Vision.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-gpt-oss-bnb-20b",
      "name": "Kaggle Gpt Oss Bnb (20B) Inference",
      "description": "Fine-tune Kaggle Gpt Oss Bnb (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-GPT_OSS_BNB_(20B)-Inference.ipynb",
      "path": "kaggle-gpt-oss-bnb-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-GPT_OSS_BNB_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:25:56.642122+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-GPT_OSS_BNB_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "kaggle-gpt-oss-mxfp4-20b",
      "name": "Kaggle Gpt Oss Mxfp4 (20B) Inference",
      "description": "Fine-tune Kaggle Gpt Oss Mxfp4 (20B) Inference with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-GPT_OSS_MXFP4_(20B)-Inference.ipynb",
      "path": "kaggle-gpt-oss-mxfp4-20b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-GPT_OSS_MXFP4_(20B)-Inference.ipynb",
        "last_synced": "2025-10-21T16:25:56.913798+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-GPT_OSS_MXFP4_(20B)-Inference.ipynb"
      ]
    },
    {
      "id": "kaggle-granite4",
      "name": "Kaggle Granite4",
      "description": "Fine-tune Kaggle Granite4 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Granite4.0.ipynb",
      "path": "kaggle-granite4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Granite4.ipynb",
        "last_synced": "2025-10-21T16:25:55.244642+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-Granite4.0.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-liquid-lfm2-1",
      "name": "Kaggle Liquid Lfm2 (1",
      "description": "Fine-tune Kaggle Liquid Lfm2 (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Liquid_LFM2_(1.2B)-Conversational.ipynb",
      "path": "kaggle-liquid-lfm2-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Liquid_LFM2_(1.ipynb",
        "last_synced": "2025-10-21T16:25:56.476864+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Liquid_LFM2_(1.2B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-llama3",
      "name": "Kaggle Llama3",
      "description": "Fine-tune Kaggle Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3.1_(8B)-Alpaca.ipynb",
      "path": "kaggle-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3.ipynb",
        "last_synced": "2025-10-21T16:25:57.534327+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Llama3.1_(8B)-Alpaca.ipynb",
        "Kaggle-Llama3.2_(11B)-Vision.ipynb",
        "setup.sh",
        "Kaggle-Llama3.1_(8B)-Inference.ipynb",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Llama3.2_(1B)-RAFT.ipynb",
        "Kaggle-Llama3.1_(8B)-GRPO.ipynb",
        "Kaggle-Llama3.3_(70B)_A100-Conversational.ipynb",
        "Kaggle-Llama3.2_(1B_and_3B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-llama3-8b",
      "name": "Kaggle Llama3 (8B) Conversational",
      "description": "Fine-tune Kaggle Llama3 (8B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3_(8B)-Alpaca.ipynb",
      "path": "kaggle-llama3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3_(8B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:55.367718+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-Llama3_(8B)-Alpaca.ipynb",
        "Kaggle-Llama3_(8B)-Conversational.ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llama3-8b-ollama",
      "name": "Kaggle Llama3 (8B) Ollama",
      "description": "Fine-tune Kaggle Llama3 (8B) Ollama with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3_(8B)-Ollama.ipynb",
      "path": "kaggle-llama3-8b-ollama",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3_(8B)-Ollama.ipynb",
        "last_synced": "2025-10-21T16:25:52.796043+00:00"
      },
      "files": [
        "Kaggle-Llama3_(8B)-Ollama.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llama3-8b-orpo",
      "name": "Kaggle Llama3 (8B) Orpo",
      "description": "Fine-tune Kaggle Llama3 (8B) Orpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llama3_(8B)-ORPO.ipynb",
      "path": "kaggle-llama3-8b-orpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llama3_(8B)-ORPO.ipynb",
        "last_synced": "2025-10-21T16:25:54.873109+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Llama3_(8B)-ORPO.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llasa-tts-1b",
      "name": "Kaggle Llasa Tts (1B)",
      "description": "Fine-tune Kaggle Llasa Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llasa_TTS_(1B).ipynb",
      "path": "kaggle-llasa-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llasa_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:25:55.306891+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Kaggle-Llasa_TTS_(1B).ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-llasa-tts-3b",
      "name": "Kaggle Llasa Tts (3B)",
      "description": "Fine-tune Kaggle Llasa Tts (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Llasa_TTS_(3B).ipynb",
      "path": "kaggle-llasa-tts-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Llasa_TTS_(3B).ipynb",
        "last_synced": "2025-10-21T16:25:54.850083+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Llasa_TTS_(3B).ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-magistral-24b-reasoning",
      "name": "Kaggle Magistral (24B) Reasoning Conversational",
      "description": "Fine-tune Kaggle Magistral (24B) Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb",
      "path": "kaggle-magistral-24b-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:57.852499+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-meta-synthetic-data-llama3",
      "name": "Kaggle Meta Synthetic Data Llama3",
      "description": "Fine-tune Kaggle Meta Synthetic Data Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
      "path": "kaggle-meta-synthetic-data-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Meta-Synthetic-Data-Llama3.ipynb",
        "last_synced": "2025-10-21T16:25:58.422179+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).ipynb"
      ]
    },
    {
      "id": "kaggle-meta-synthetic-data-llama3-2-3b",
      "name": "Kaggle Meta Synthetic Data Llama3 2 (3B)",
      "description": "Fine-tune Kaggle Meta Synthetic Data Llama3 2 (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
      "path": "kaggle-meta-synthetic-data-llama3-2-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "last_synced": "2025-10-21T16:25:58.128325+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb"
      ]
    },
    {
      "id": "kaggle-mistral-7b-text-completion",
      "name": "Kaggle Mistral (7B) Text Completion",
      "description": "Fine-tune Kaggle Mistral (7B) Text Completion with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_(7B)-Text_Completion.ipynb",
      "path": "kaggle-mistral-7b-text-completion",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_(7B)-Text_Completion.ipynb",
        "last_synced": "2025-10-21T16:25:52.568265+00:00"
      },
      "files": [
        "Kaggle-Mistral_(7B)-Text_Completion.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-mistral-nemo-12b",
      "name": "Kaggle Mistral Nemo (12B) Alpaca",
      "description": "Fine-tune Kaggle Mistral Nemo (12B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb",
      "path": "kaggle-mistral-nemo-12b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:53.749712+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-mistral-small-22b",
      "name": "Kaggle Mistral Small (22B) Alpaca",
      "description": "Fine-tune Kaggle Mistral Small (22B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_Small_(22B)-Alpaca.ipynb",
      "path": "kaggle-mistral-small-22b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_Small_(22B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:52.756783+00:00"
      },
      "files": [
        "Kaggle-Mistral_Small_(22B)-Alpaca.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-mistral-v0",
      "name": "Kaggle Mistral V0",
      "description": "Fine-tune Kaggle Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Mistral_v0.3_(7B)-Conversational.ipynb",
      "path": "kaggle-mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Mistral_v0.ipynb",
        "last_synced": "2025-10-21T16:25:58.931081+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Mistral_v0.3_(7B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Mistral_v0.3_(7B)-CPT.ipynb",
        "Kaggle-Mistral_v0.3_(7B)-GRPO.ipynb",
        "Kaggle-Mistral_v0.3_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "kaggle-orpheus-3b-tts",
      "name": "Kaggle Orpheus (3B) Tts",
      "description": "Fine-tune Kaggle Orpheus (3B) Tts with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Orpheus_(3B)-TTS.ipynb",
      "path": "kaggle-orpheus-3b-tts",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Orpheus_(3B)-TTS.ipynb",
        "last_synced": "2025-10-21T16:25:53.540603+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Orpheus_(3B)-TTS.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-oute-tts-1b",
      "name": "Kaggle Oute Tts (1B)",
      "description": "Fine-tune Kaggle Oute Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Oute_TTS_(1B).ipynb",
      "path": "kaggle-oute-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Oute_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:25:57.079354+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Oute_TTS_(1B).ipynb"
      ]
    },
    {
      "id": "kaggle-phi-3",
      "name": "Kaggle Phi 3",
      "description": "Fine-tune Kaggle Phi 3 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_3.5_Mini-Conversational.ipynb",
      "path": "kaggle-phi-3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Phi_3.ipynb",
        "last_synced": "2025-10-21T16:25:57.456304+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_3.5_Mini-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-phi-3-medium",
      "name": "Kaggle Phi 3 Medium Conversational",
      "description": "Fine-tune Kaggle Phi 3 Medium Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_3_Medium-Conversational.ipynb",
      "path": "kaggle-phi-3-medium",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Phi_3_Medium-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:58.497120+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_3_Medium-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-phi-4",
      "name": "Kaggle Phi 4 Conversational",
      "description": "Fine-tune Kaggle Phi 4 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Phi_4-Conversational.ipynb",
      "path": "kaggle-phi-4",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Phi_4-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:57.722980+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Phi_4-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-pixtral-12b-vision",
      "name": "Kaggle Pixtral (12B) Vision",
      "description": "Fine-tune Kaggle Pixtral (12B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Pixtral_(12B)-Vision.ipynb",
      "path": "kaggle-pixtral-12b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Pixtral_(12B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:25:52.168139+00:00"
      },
      "files": [
        "Kaggle-Pixtral_(12B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-qwen2",
      "name": "Kaggle Qwen2",
      "description": "Fine-tune Kaggle Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2.5_VL_(7B)-Vision.ipynb",
      "path": "kaggle-qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2.ipynb",
        "last_synced": "2025-10-21T16:25:57.810482+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Qwen2.5_VL_(7B)-Vision.ipynb",
        "setup.sh",
        "Kaggle-Qwen2.5_(7B)-Alpaca.ipynb",
        "README.md",
        "Kaggle-Qwen2.5_(3B)-GRPO.ipynb",
        "docker-compose.yml",
        "Kaggle-Qwen2.5_Coder_(14B)-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen2-7b",
      "name": "Kaggle Qwen2 (7B) Alpaca",
      "description": "Fine-tune Kaggle Qwen2 (7B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2_(7B)-Alpaca.ipynb",
      "path": "kaggle-qwen2-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_(7B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:54.032969+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Qwen2_(7B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-qwen2-5-7b-vl",
      "name": "Kaggle Qwen2 5 7B Vl Grpo",
      "description": "Fine-tune Kaggle Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "kaggle-qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:57.268364+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen2_5_7B_VL_GRPO.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen2-vl-7b-vision",
      "name": "Kaggle Qwen2 Vl (7B) Vision",
      "description": "Fine-tune Kaggle Qwen2 Vl (7B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2_VL_(7B)-Vision.ipynb",
      "path": "kaggle-qwen2-vl-7b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_VL_(7B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:25:55.811013+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen2_VL_(7B)-Vision.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen2.5-coder-1",
      "name": "Kaggle Qwen2.5 Coder (1",
      "description": "Fine-tune Kaggle Qwen2.5 Coder (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
      "path": "kaggle-qwen2.5-coder-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2.5_Coder_(1.ipynb",
        "last_synced": "2025-10-21T16:25:56.804446+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen3-32b-a100-reasoning",
      "name": "Kaggle Qwen3 (32B) A100 Reasoning Conversational",
      "description": "Fine-tune Kaggle Qwen3 (32B) A100 Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
      "path": "kaggle-qwen3-32b-a100-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:56.146000+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen3-4b",
      "name": "Kaggle Qwen3 (4B) Grpo",
      "description": "Fine-tune Kaggle Qwen3 (4B) Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(4B)-GRPO.ipynb",
      "path": "kaggle-qwen3-4b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(4B)-GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:58.361151+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(4B)-GRPO.ipynb"
      ]
    },
    {
      "id": "kaggle-qwen3-4b-instruct",
      "name": "Kaggle Qwen3 (4B) Instruct",
      "description": "Fine-tune Kaggle Qwen3 (4B) Instruct with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(4B)-Instruct.ipynb",
      "path": "kaggle-qwen3-4b-instruct",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(4B)-Instruct.ipynb",
        "last_synced": "2025-10-21T16:25:52.838162+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-Qwen3_(4B)-Instruct.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-qwen3-4b-thinking",
      "name": "Kaggle Qwen3 (4B) Thinking",
      "description": "Fine-tune Kaggle Qwen3 (4B) Thinking with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Qwen3_(4B)-Thinking.ipynb",
      "path": "kaggle-qwen3-4b-thinking",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen3_(4B)-Thinking.ipynb",
        "last_synced": "2025-10-21T16:25:58.453798+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_(4B)-Thinking.ipynb"
      ]
    },
    {
      "id": "kaggle-spark-tts-0-5b",
      "name": "Kaggle Spark Tts (0 5B)",
      "description": "Fine-tune Kaggle Spark Tts (0 5B) with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Spark_TTS_(0_5B).ipynb",
      "path": "kaggle-spark-tts-0-5b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Spark_TTS_(0_5B).ipynb",
        "last_synced": "2025-10-21T16:25:57.660322+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Spark_TTS_(0_5B).ipynb"
      ]
    },
    {
      "id": "kaggle-tinyllama-1",
      "name": "Kaggle Tinyllama (1",
      "description": "Fine-tune Kaggle Tinyllama (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-TinyLlama_(1.1B)-Alpaca.ipynb",
      "path": "kaggle-tinyllama-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-TinyLlama_(1.ipynb",
        "last_synced": "2025-10-21T16:25:54.332830+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Kaggle-TinyLlama_(1.1B)-Alpaca.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "kaggle-unsloth-studio",
      "name": "Kaggle Unsloth Studio",
      "description": "Fine-tune Kaggle Unsloth Studio with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Unsloth_Studio.ipynb",
      "path": "kaggle-unsloth-studio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Unsloth_Studio.ipynb",
        "last_synced": "2025-10-21T16:25:56.001243+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Unsloth_Studio.ipynb"
      ]
    },
    {
      "id": "kaggle-whisper",
      "name": "Kaggle Whisper",
      "description": "Fine-tune Kaggle Whisper with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Whisper.ipynb",
      "path": "kaggle-whisper",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Whisper.ipynb",
        "last_synced": "2025-10-21T16:25:56.713073+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Whisper.ipynb"
      ]
    },
    {
      "id": "kaggle-zephyr-7b-dpo",
      "name": "Kaggle Zephyr (7B) Dpo",
      "description": "Fine-tune Kaggle Zephyr (7B) Dpo with Unsloth on NVIDIA GPUs",
      "notebook": "Kaggle-Zephyr_(7B)-DPO.ipynb",
      "path": "kaggle-zephyr-7b-dpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Zephyr_(7B)-DPO.ipynb",
        "last_synced": "2025-10-21T16:25:57.489924+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Zephyr_(7B)-DPO.ipynb"
      ]
    },
    {
      "id": "liquid-lfm2-1",
      "name": "Liquid Lfm2 (1",
      "description": "Fine-tune Liquid Lfm2 (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Liquid_LFM2_(1.2B)-Conversational.ipynb",
      "path": "liquid-lfm2-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Liquid_LFM2_(1.ipynb",
        "last_synced": "2025-10-21T16:25:52.947045+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Liquid_LFM2_(1.2B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "liquid-lfm2",
      "name": "Liquid Lfm2 Conversational",
      "description": "Fine-tune Liquid Lfm2 Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Liquid_LFM2-Conversational.ipynb",
      "path": "liquid-lfm2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Liquid_LFM2-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:57.996812+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Liquid_LFM2-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3",
      "name": "Llama3",
      "description": "Fine-tune Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3.2_(11B)-Vision.ipynb",
      "path": "llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3.ipynb",
        "last_synced": "2025-10-21T16:25:57.577603+00:00"
      },
      "files": [
        "Llama3.2_(11B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Llama3.2_(1B_and_3B)-Conversational.ipynb",
        "README.md",
        "Llama3.1_(8B)-GRPO.ipynb",
        "docker-compose.yml",
        "Llama3.2_(1B)-RAFT.ipynb",
        "Llama3.1_(8B)-Alpaca.ipynb",
        "Llama3.3_(70B)_A100-Conversational.ipynb",
        "Llama3.1_(8B)-Inference.ipynb"
      ]
    },
    {
      "id": "llama3-8b",
      "name": "Llama3 (8B) Conversational",
      "description": "Fine-tune Llama3 (8B) Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Alpaca.ipynb",
      "path": "llama3-8b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:58.298873+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Llama3_(8B)-Alpaca.ipynb",
        "Llama3_(8B)-Conversational.ipynb"
      ]
    },
    {
      "id": "llama3-8b-ollama",
      "name": "Llama3 (8B) Ollama",
      "description": "Fine-tune Llama3 (8B) Ollama with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-Ollama.ipynb",
      "path": "llama3-8b-ollama",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb",
        "last_synced": "2025-10-21T16:25:53.502012+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Llama3_(8B)-Ollama.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "llama3-8b-orpo",
      "name": "Llama3 (8B) Orpo",
      "description": "Fine-tune Llama3 (8B) Orpo with Unsloth on NVIDIA GPUs",
      "notebook": "Llama3_(8B)-ORPO.ipynb",
      "path": "llama3-8b-orpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llama3_(8B)-ORPO.ipynb",
        "last_synced": "2025-10-21T16:25:52.878838+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Llama3_(8B)-ORPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "llasa-tts-1b",
      "name": "Llasa Tts (1B)",
      "description": "Fine-tune Llasa Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Llasa_TTS_(1B).ipynb",
      "path": "llasa-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llasa_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:25:55.179356+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Llasa_TTS_(1B).ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "llasa-tts-3b",
      "name": "Llasa Tts (3B)",
      "description": "Fine-tune Llasa Tts (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Llasa_TTS_(3B).ipynb",
      "path": "llasa-tts-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Llasa_TTS_(3B).ipynb",
        "last_synced": "2025-10-21T16:25:52.314015+00:00"
      },
      "files": [
        "Llasa_TTS_(3B).ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "magistral-24b-reasoning",
      "name": "Magistral (24B) Reasoning Conversational",
      "description": "Fine-tune Magistral (24B) Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Magistral_(24B)-Reasoning-Conversational.ipynb",
      "path": "magistral-24b-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Magistral_(24B)-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:52.910647+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Magistral_(24B)-Reasoning-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "meta-synthetic-data-llama3",
      "name": "Meta Synthetic Data Llama3",
      "description": "Fine-tune Meta Synthetic Data Llama3 with Unsloth on NVIDIA GPUs",
      "notebook": "Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
      "path": "meta-synthetic-data-llama3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Meta-Synthetic-Data-Llama3.ipynb",
        "last_synced": "2025-10-21T16:25:55.566150+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "Meta-Synthetic-Data-Llama3.1_(8B).ipynb",
        "docker-compose.yml"
      ]
    },
    {
      "id": "meta-synthetic-data-llama3-2-3b",
      "name": "Meta Synthetic Data Llama3 2 (3B)",
      "description": "Fine-tune Meta Synthetic Data Llama3 2 (3B) with Unsloth on NVIDIA GPUs",
      "notebook": "Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
      "path": "meta-synthetic-data-llama3-2-3b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "last_synced": "2025-10-21T16:25:53.341452+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Meta_Synthetic_Data_Llama3_2_(3B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "mistral-7b-text-completion",
      "name": "Mistral (7B) Text Completion",
      "description": "Fine-tune Mistral (7B) Text Completion with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_(7B)-Text_Completion.ipynb",
      "path": "mistral-7b-text-completion",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb",
        "last_synced": "2025-10-21T16:25:56.879263+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_(7B)-Text_Completion.ipynb"
      ]
    },
    {
      "id": "mistral-nemo-12b",
      "name": "Mistral Nemo (12B) Alpaca",
      "description": "Fine-tune Mistral Nemo (12B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_Nemo_(12B)-Alpaca.ipynb",
      "path": "mistral-nemo-12b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_Nemo_(12B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:54.491488+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Mistral_Nemo_(12B)-Alpaca.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "mistral-small-22b",
      "name": "Mistral Small (22B) Alpaca",
      "description": "Fine-tune Mistral Small (22B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_Small_(22B)-Alpaca.ipynb",
      "path": "mistral-small-22b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_Small_(22B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:57.684775+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_Small_(22B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "mistral-v0",
      "name": "Mistral V0",
      "description": "Fine-tune Mistral V0 with Unsloth on NVIDIA GPUs",
      "notebook": "Mistral_v0.3_(7B)-CPT.ipynb",
      "path": "mistral-v0",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Mistral_v0.ipynb",
        "last_synced": "2025-10-21T16:25:58.031956+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Mistral_v0.3_(7B)-CPT.ipynb",
        "Mistral_v0.3_(7B)-GRPO.ipynb",
        "Mistral_v0.3_(7B)-Conversational.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Mistral_v0.3_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "orpheus-3b-tts",
      "name": "Orpheus (3B) Tts",
      "description": "Fine-tune Orpheus (3B) Tts with Unsloth on NVIDIA GPUs",
      "notebook": "Orpheus_(3B)-TTS.ipynb",
      "path": "orpheus-3b-tts",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Orpheus_(3B)-TTS.ipynb",
        "last_synced": "2025-10-21T16:25:55.030126+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Orpheus_(3B)-TTS.ipynb",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "oute-tts-1b",
      "name": "Oute Tts (1B)",
      "description": "Fine-tune Oute Tts (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Oute_TTS_(1B).ipynb",
      "path": "oute-tts-1b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Oute_TTS_(1B).ipynb",
        "last_synced": "2025-10-21T16:25:53.310971+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Oute_TTS_(1B).ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "phi-3",
      "name": "Phi 3",
      "description": "Fine-tune Phi 3 with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_3.5_Mini-Conversational.ipynb",
      "path": "phi-3",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi_3.ipynb",
        "last_synced": "2025-10-21T16:25:58.161206+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_3.5_Mini-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-3-medium",
      "name": "Phi 3 Medium Conversational",
      "description": "Fine-tune Phi 3 Medium Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_3_Medium-Conversational.ipynb",
      "path": "phi-3-medium",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi_3_Medium-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:58.088878+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_3_Medium-Conversational.ipynb"
      ]
    },
    {
      "id": "phi-4-14b-fine-tuning",
      "name": "Phi-4 (14B)",
      "description": "Fine-tune Phi-4 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Phi_4-Conversational.ipynb",
      "path": "phi-4-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Phi-4_(14B).ipynb",
        "last_synced": "2025-10-21T16:25:58.329299+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Phi_4-Conversational.ipynb",
        "Kaggle-Phi_4_(14B)-GRPO.ipynb",
        "Phi_4_(14B)-GRPO.ipynb",
        "HuggingFace Course-Phi_4_(14B)-GRPO.ipynb"
      ]
    },
    {
      "id": "pixtral-12b-vision",
      "name": "Pixtral (12B) Vision",
      "description": "Fine-tune Pixtral (12B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Pixtral_(12B)-Vision.ipynb",
      "path": "pixtral-12b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:25:54.366405+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Pixtral_(12B)-Vision.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen2",
      "name": "Qwen2",
      "description": "Fine-tune Qwen2 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_VL_(7B)-Vision.ipynb",
      "path": "qwen2",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.ipynb",
        "last_synced": "2025-10-21T16:25:56.977233+00:00"
      },
      "files": [
        "Qwen2.5_VL_(7B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "Qwen2.5_(7B)-Alpaca.ipynb",
        "setup.sh",
        "Qwen2.5_(3B)-GRPO.ipynb",
        "README.md",
        "docker-compose.yml",
        "Qwen2.5_Coder_(14B)-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen2-7b",
      "name": "Qwen2 (7B) Alpaca",
      "description": "Fine-tune Qwen2 (7B) Alpaca with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_(7B)-Alpaca.ipynb",
      "path": "qwen2-7b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_(7B)-Alpaca.ipynb",
        "last_synced": "2025-10-21T16:25:55.775678+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen2_(7B)-Alpaca.ipynb"
      ]
    },
    {
      "id": "qwen2-5-7b-vl",
      "name": "Qwen2 5 7B Vl Grpo",
      "description": "Fine-tune Qwen2 5 7B Vl Grpo with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_5_7B_VL_GRPO.ipynb",
      "path": "qwen2-5-7b-vl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb",
        "last_synced": "2025-10-21T16:25:53.206624+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Qwen2_5_7B_VL_GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen2-vl-7b-vision",
      "name": "Qwen2 Vl (7B) Vision",
      "description": "Fine-tune Qwen2 Vl (7B) Vision with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2_VL_(7B)-Vision.ipynb",
      "path": "qwen2-vl-7b-vision",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb",
        "last_synced": "2025-10-21T16:25:52.524817+00:00"
      },
      "files": [
        "Qwen2_VL_(7B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen2.5-coder-1",
      "name": "Qwen2.5 Coder (1",
      "description": "Fine-tune Qwen2.5 Coder (1 with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
      "path": "qwen2.5-coder-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_(1.ipynb",
        "last_synced": "2025-10-21T16:25:52.716357+00:00"
      },
      "files": [
        "Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "qwen3-14b-fine-tuning",
      "name": "Qwen3 (14B)",
      "description": "Fine-tune Qwen3 (14B) with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(14B)-Alpaca.ipynb",
      "path": "qwen3-14b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "text-generation",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(14B).ipynb",
        "last_synced": "2025-10-21T16:25:58.817121+00:00"
      },
      "files": [
        "Qwen3_(14B)-Alpaca.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "Kaggle-Qwen3_(14B)-Alpaca.ipynb",
        "README.md",
        "Kaggle-Qwen3_(14B).ipynb",
        "docker-compose.yml",
        "Kaggle-Qwen3_(14B)-Reasoning-Conversational.ipynb",
        "Qwen3_(14B).ipynb",
        "Qwen3_(14B)-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-32b-a100-reasoning",
      "name": "Qwen3 (32B) A100 Reasoning Conversational",
      "description": "Fine-tune Qwen3 (32B) A100 Reasoning Conversational with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
      "path": "qwen3-32b-a100-reasoning",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(32B)_A100-Reasoning-Conversational.ipynb",
        "last_synced": "2025-10-21T16:25:56.557254+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(32B)_A100-Reasoning-Conversational.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-grpo-rl",
      "name": "Qwen3 (4B) GRPO",
      "description": "Fine-tune Qwen3 (4B) GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-GRPO.ipynb",
      "path": "qwen3-4b-grpo-rl",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reinforcement-learning",
        "grpo",
        "reasoning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)_grpo.ipynb",
        "last_synced": "2025-10-21T16:25:58.871129+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-GRPO.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-instruct",
      "name": "Qwen3 (4B) Instruct",
      "description": "Fine-tune Qwen3 (4B) Instruct with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-Instruct.ipynb",
      "path": "qwen3-4b-instruct",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-Instruct.ipynb",
        "last_synced": "2025-10-21T16:25:57.766839+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-Instruct.ipynb"
      ]
    },
    {
      "id": "qwen3-4b-thinking",
      "name": "Qwen3 (4B) Thinking",
      "description": "Fine-tune Qwen3 (4B) Thinking with Unsloth on NVIDIA GPUs",
      "notebook": "Qwen3_(4B)-Thinking.ipynb",
      "path": "qwen3-4b-thinking",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-Thinking.ipynb",
        "last_synced": "2025-10-21T16:25:56.195016+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Qwen3_(4B)-Thinking.ipynb"
      ]
    },
    {
      "id": "qwen3-vl-8b-vision",
      "name": "Qwen3-VL (8B)",
      "description": "Fine-tune Qwen3-VL (8B) with Unsloth on NVIDIA GPUs",
      "notebook": "HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
      "path": "qwen3-vl-8b-vision",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "vision",
        "multimodal",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Qwen3-VL_(8B).ipynb",
        "last_synced": "2025-10-21T16:25:58.792831+00:00"
      },
      "files": [
        "HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
        "Kaggle-Qwen3_VL_(8B)-Vision.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "Qwen3_VL_(8B)-Vision-GRPO.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Qwen3_VL_(8B)-Vision-GRPO.ipynb",
        "Qwen3_VL_(8B)-Vision.ipynb"
      ]
    },
    {
      "id": "sesame-csm-1b-tts",
      "name": "Sesame-CSM (1B)",
      "description": "Fine-tune Sesame-CSM (1B) with Unsloth on NVIDIA GPUs",
      "notebook": "Sesame_CSM_(1B)-TTS.ipynb",
      "path": "sesame-csm-1b-tts",
      "gpu": {
        "tier": "T4",
        "min_vram_gb": 12,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "text-to-speech",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Sesame-CSM_(1B).ipynb",
        "last_synced": "2025-10-21T16:25:56.941985+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Sesame_CSM_(1B)-TTS.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-Sesame_CSM_(1B)-TTS.ipynb"
      ]
    },
    {
      "id": "spark-tts-0-5b",
      "name": "Spark Tts (0 5B)",
      "description": "Fine-tune Spark Tts (0 5B) with Unsloth on NVIDIA GPUs",
      "notebook": "Spark_TTS_(0_5B).ipynb",
      "path": "spark-tts-0-5b",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Spark_TTS_(0_5B).ipynb",
        "last_synced": "2025-10-21T16:25:55.593306+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Spark_TTS_(0_5B).ipynb"
      ]
    },
    {
      "id": "synthetic-data-hackathon",
      "name": "Synthetic Data Hackathon",
      "description": "Fine-tune Synthetic Data Hackathon with Unsloth on NVIDIA GPUs",
      "notebook": "Synthetic_Data_Hackathon.ipynb",
      "path": "synthetic-data-hackathon",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Synthetic_Data_Hackathon.ipynb",
        "last_synced": "2025-10-21T16:25:57.563675+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Synthetic_Data_Hackathon.ipynb"
      ]
    },
    {
      "id": "tinyllama-1",
      "name": "Tinyllama (1",
      "description": "Fine-tune Tinyllama (1 with Unsloth on NVIDIA GPUs",
      "notebook": "TinyLlama_(1.1B)-Alpaca.ipynb",
      "path": "tinyllama-1",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/TinyLlama_(1.ipynb",
        "last_synced": "2025-10-21T16:25:52.377896+00:00"
      },
      "files": [
        "TinyLlama_(1.1B)-Alpaca.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "unsloth-studio",
      "name": "Unsloth Studio",
      "description": "Fine-tune Unsloth Studio with Unsloth on NVIDIA GPUs",
      "notebook": "Unsloth_Studio.ipynb",
      "path": "unsloth-studio",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb",
        "last_synced": "2025-10-21T16:25:52.640511+00:00"
      },
      "files": [
        "Unsloth_Studio.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "whisper-large-v3-stt",
      "name": "Whisper Large V3",
      "description": "Fine-tune Whisper Large V3 with Unsloth on NVIDIA GPUs",
      "notebook": "Whisper.ipynb",
      "path": "whisper-large-v3-stt",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "audio",
        "speech-to-text",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Whisper_Large_V3.ipynb",
        "last_synced": "2025-10-21T16:25:53.157997+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "Whisper.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml"
      ]
    },
    {
      "id": "zephyr-7b-dpo",
      "name": "Zephyr (7B) Dpo",
      "description": "Fine-tune Zephyr (7B) Dpo with Unsloth on NVIDIA GPUs",
      "notebook": "Zephyr_(7B)-DPO.ipynb",
      "path": "zephyr-7b-dpo",
      "gpu": {
        "tier": "L4",
        "min_vram_gb": 16,
        "multi_gpu": false
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "fine-tuning"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/Zephyr_(7B)-DPO.ipynb",
        "last_synced": "2025-10-21T16:25:57.158979+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Zephyr_(7B)-DPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-120b-fine-tuning",
      "name": "gpt-oss-120b",
      "description": "Fine-tune gpt-oss-120b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt-oss-(120B)_A100-Fine-tuning.ipynb",
      "path": "gpt-oss-120b-fine-tuning",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 80,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-120b.ipynb",
        "last_synced": "2025-10-21T16:25:58.197436+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "gpt-oss-(120B)_A100-Fine-tuning.ipynb",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(120B)_A100-Fine-tuning.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-fine-tuning",
      "name": "gpt-oss-20b",
      "description": "Fine-tune gpt-oss-20b with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark.ipynb",
      "path": "gpt-oss-20b-fine-tuning",
      "gpu": {
        "tier": "A100-40GB",
        "min_vram_gb": 24,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "fine-tuning",
        "large-model"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b.ipynb",
        "last_synced": "2025-10-21T16:25:58.966040+00:00"
      },
      "files": [
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_DGX_Spark.ipynb",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game.ipynb",
        "Kaggle-gpt-oss-(20B)_A100-GRPO.ipynb",
        ".brevconfig.json",
        "requirements.txt",
        "gpt-oss-(20B)_A100-GRPO.ipynb",
        "gpt-oss-(20B)-GRPO.ipynb",
        "HuggingFace Course-gpt-oss-(20B)_A100-GRPO.ipynb",
        "setup.sh",
        "gpt_oss_(20B)_Reinforcement_Learning_2048_Game_BF16.ipynb",
        "README.md",
        "gpt-oss-(20B)-Fine-tuning.ipynb",
        "docker-compose.yml",
        "Kaggle-gpt-oss-(20B)-GRPO.ipynb",
        "Kaggle-gpt-oss-(20B)-Fine-tuning.ipynb",
        "HuggingFace Course-gpt-oss-(20B)-GRPO.ipynb"
      ]
    },
    {
      "id": "gpt-oss-20b-grpo-rl",
      "name": "gpt-oss-20b-GRPO",
      "description": "Fine-tune gpt-oss-20b-GRPO with Unsloth on NVIDIA GPUs",
      "notebook": "gpt_oss_(20B)_GRPO_BF16.ipynb",
      "path": "gpt-oss-20b-grpo-rl",
      "gpu": {
        "tier": "A100-80GB",
        "min_vram_gb": 40,
        "multi_gpu": true
      },
      "tags": [
        "unsloth",
        "fine-tuning",
        "reasoning",
        "reinforcement-learning",
        "grpo"
      ],
      "upstream": {
        "source": "unslothai/notebooks",
        "notebook_url": "https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-20b-grpo.ipynb",
        "last_synced": "2025-10-21T16:25:56.756997+00:00"
      },
      "files": [
        ".brevconfig.json",
        "requirements.txt",
        "setup.sh",
        "README.md",
        "docker-compose.yml",
        "gpt_oss_(20B)_GRPO_BF16.ipynb"
      ]
    }
  ]
}