{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a863b0",
   "metadata": {},
   "source": [
    "# ü§ô Pixtral (12B) Vision on NVIDIA Brev\n",
    "\n",
    "<div style=\"background: linear-gradient(90deg, #00ff87 0%, #60efff 100%); padding: 1px; border-radius: 8px; margin: 20px 0;\">\n",
    "    <div style=\"background: #0a0a0a; padding: 20px; border-radius: 7px;\">\n",
    "        <p style=\"color: #60efff; margin: 0;\"><strong>‚ö° Powered by Brev</strong> | Converted from <a href=\"https://github.com/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb\" style=\"color: #00ff87;\">Unsloth Notebook</a></p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "## üìã Configuration\n",
    "\n",
    "<table style=\"width: auto; margin-left: 0; border-collapse: collapse; border: 2px solid #808080;\">\n",
    "    <thead>\n",
    "        <tr style=\"border-bottom: 2px solid #808080;\">\n",
    "            <th style=\"text-align: left; padding: 8px 12px; border-right: 2px solid #808080; font-weight: bold;\">Parameter</th>\n",
    "            <th style=\"text-align: left; padding: 8px 12px; font-weight: bold;\">Value</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid #808080;\"><strong>Model</strong></td>\n",
    "            <td style=\"text-align: left; padding: 8px 12px;\">Pixtral (12B) Vision</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid #808080;\"><strong>Recommended GPU</strong></td>\n",
    "            <td style=\"text-align: left; padding: 8px 12px;\">L4</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid #808080;\"><strong>Min VRAM</strong></td>\n",
    "            <td style=\"text-align: left; padding: 8px 12px;\">16 GB</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid #808080;\"><strong>Batch Size</strong></td>\n",
    "            <td style=\"text-align: left; padding: 8px 12px;\">2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid #808080;\"><strong>Categories</strong></td>\n",
    "            <td style=\"text-align: left; padding: 8px 12px;\">fine-tuning</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "## üîß Key Adaptations for Brev\n",
    "\n",
    "- ‚úÖ Replaced Colab-specific installation with conda-based Unsloth\n",
    "- ‚úÖ Converted magic commands to subprocess calls\n",
    "- ‚úÖ Removed Google Drive dependencies\n",
    "- ‚úÖ Updated paths from `/workspace/` to `/workspace/`\n",
    "- ‚úÖ Added `device_map=\"auto\"` for multi-GPU support\n",
    "- ‚úÖ Optimized batch sizes for NVIDIA GPUs\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [Unsloth Documentation](https://docs.unsloth.ai/)\n",
    "- [Brev Documentation](https://docs.nvidia.com/brev)\n",
    "- [Original Notebook](https://github.com/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
    "</div>\n",
    "\n",
    "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
    "\n",
    "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
    "\n",
    "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
    "\n",
    "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
    "\n",
    "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Check for Brev\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Configure PyTorch cache directories to avoid permission errors\n",
    "# MUST be set before any torch imports\n",
    "# Prefer /ephemeral for Brev instances (larger scratch space)\n",
    "\n",
    "# Test if /ephemeral exists and is actually writable (not just readable)\n",
    "use_ephemeral = False\n",
    "if os.path.exists(\"/ephemeral\"):\n",
    "    try:\n",
    "        test_file = \"/ephemeral/.write_test\"\n",
    "        with open(test_file, \"w\") as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        use_ephemeral = True\n",
    "    except (PermissionError, OSError):\n",
    "        pass\n",
    "\n",
    "if use_ephemeral:\n",
    "    cache_base = \"/ephemeral/torch_cache\"\n",
    "    triton_cache = \"/ephemeral/triton_cache\"\n",
    "    tmpdir = \"/ephemeral/tmp\"\n",
    "    print(\"Using /ephemeral for cache (Brev scratch space)\")\n",
    "else:\n",
    "    cache_base = os.path.expanduser(\"~/.cache/torch/inductor\")\n",
    "    triton_cache = os.path.expanduser(\"~/.cache/triton\")\n",
    "    tmpdir = os.path.expanduser(\"~/.cache/tmp\")\n",
    "    print(\"Using home directory for cache\")\n",
    "\n",
    "# Set ALL PyTorch/Triton cache and temp directories\n",
    "os.environ[\"TORCHINDUCTOR_CACHE_DIR\"] = cache_base\n",
    "os.environ[\"TORCH_COMPILE_DIR\"] = cache_base\n",
    "os.environ[\"TRITON_CACHE_DIR\"] = triton_cache\n",
    "os.environ[\"XDG_CACHE_HOME\"] = os.path.expanduser(\"~/.cache\")\n",
    "os.environ[\"TMPDIR\"] = tmpdir  # Override system /tmp\n",
    "os.environ[\"TEMP\"] = tmpdir\n",
    "os.environ[\"TMP\"] = tmpdir\n",
    "\n",
    "# Create cache directories with proper permissions (777 to ensure writability)\n",
    "for cache_dir in [cache_base, triton_cache, tmpdir, os.environ[\"XDG_CACHE_HOME\"]]:\n",
    "    os.makedirs(cache_dir, mode=0o777, exist_ok=True)\n",
    "\n",
    "# Clean up any old compiled caches that point to /tmp\n",
    "old_cache = os.path.join(os.getcwd(), \"unsloth_compiled_cache\")\n",
    "if os.path.exists(old_cache):\n",
    "    print(f\"‚ö†Ô∏è  Removing old compiled cache: {old_cache}\")\n",
    "    shutil.rmtree(old_cache, ignore_errors=True)\n",
    "\n",
    "print(f\"‚úÖ PyTorch cache: {cache_base}\")\n",
    "\n",
    "try:\n",
    "    from unsloth import FastLanguageModel\n",
    "    print(\"\\n‚úÖ Unsloth already available\")\n",
    "    print(f\"   Location: {FastLanguageModel.__module__}\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Unsloth not found - will install\")\n",
    "\n",
    "# Install unsloth using uv (the package manager for this environment)\n",
    "import subprocess\n",
    "\n",
    "print(f\"\\nInstalling packages into: {sys.executable}\")\n",
    "print(\"Using uv package manager...\\n\")\n",
    "\n",
    "try:\n",
    "    # Use uv to install packages into the current environment\n",
    "    subprocess.check_call([\"uv\", \"pip\", \"install\", \"unsloth\"])\n",
    "    subprocess.check_call([\"uv\", \"pip\", \"install\", \"transformers==4.56.2\"])\n",
    "    subprocess.check_call([\"uv\", \"pip\", \"install\", \"--no-deps\", \"trl==0.22.2\"])\n",
    "    print(\"\\n‚úÖ Installation complete\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå 'uv' command not found. Trying alternative method...\")\n",
    "    # Fallback: install pip into venv first, then use it\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"ensurepip\", \"--upgrade\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"unsloth\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers==4.56.2\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-deps\", \"trl==0.22.2\"])\n",
    "    print(\"\\n‚úÖ Installation complete\")\n",
    "\n",
    "# Verify installation\n",
    "try:\n",
    "    from unsloth import FastLanguageModel\n",
    "    print(\"‚úÖ Unsloth is now available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Installation failed: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Please restart kernel and try again\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543,
     "referenced_widgets": [
      "8a0ce0af1025429cb3cfcc5b973a4af0",
      "6fe6ac6a53f745c5a2736e1b6cb01ff7",
      "8d93c4b87f69485e8e97192a8431113f",
      "08af812d04fe481fa84e85a6a591c506",
      "257fe2a05570417882a606b304087a21",
      "6d8e442e771d4955a29a360dee525119",
      "00a911ef0d7f4a6d8b1b4f972b0b4d7c",
      "766a605b2c5a463d977b8fefb554fea5",
      "54ae26be14bc4fb28933af46f45e023a",
      "360f3db84aac4728861b74b5a37adcaa",
      "a2ae977cf14c461e9fa0cbc5c27e7186",
      "d401dcde88274752b4f0786f834527d9",
      "5d10ef16c7154f5392519da3ff6a2f0d",
      "d8358c67c0b0415098b3e4a4e7ad0cbb",
      "4f593d75532d4087bafc02d6ad2b4f79",
      "a519350329d04d5096ccb605c9ffd623",
      "9cd924df198145ed93d9df07249236cb",
      "a01af94f415b4ed18186fa099c3ecbc3",
      "27cd2e02e78d4ef8a52ba73a9e214120",
      "841f197cba3f455d8fe9a9dafac992d7",
      "d6507d692f9743e6b3eed08df94e2a56",
      "c3438845441142fa92fec3acd21b3955",
      "eb64d7acd375493098e1f7c30e7f2781",
      "ad01bece3f444f1382988a65833bebf7",
      "281b9b2311e5460aa4df9bbe9f8e22f0",
      "34afc68bfe9d4e47ad73b31a34a74b32",
      "23c9c94b98f141e8827c37cd26b6138e",
      "d2b5a8a0c51c4d04aa1da73a56c2bcd3",
      "4587ddab1af04157b8cba09f780ce9b0",
      "aab82ec73c0b42fb928fbc74fc44c168",
      "45f90f73051b4f898666ecd14f2818f0",
      "6f96f236961344418015be410aedc57c",
      "6105cefd94bb4a07b9123e461e857c9c",
      "d4d3c9f1f54746d8895b66b6d2888ee2",
      "eaa7a98acf704791a5c3ca37232c94b9",
      "7b1f0430e15a476eb4b59fd5ddb0f9ac",
      "481ce6bb0bf74e9592b5a4ef6cbc6d33",
      "7a35df90dc40472eb0862deb368da362",
      "d4bda244da214ee497b82608944bce6e",
      "2cd8ad1cedb0484fa4c5d47b7b25971c",
      "68c0b7aee1464e78b1bbd420f540fcf4",
      "1fd521ec517348aa9d8dd73757619da4",
      "9c967803321d4ca39b663165c2ce1953",
      "c39f8980d63a4a5ab17f031e06b03f67",
      "b60b17cb67044a82b173f94d781d5174",
      "9078d37b65424033b551caf1ae410d2f",
      "e5d3e2d9fb7e4f8fbfa84ba66ea0a81c",
      "ae50ac57cecb48cb917a2a3ddf3312d0",
      "2a85749ab4144e01bb640cd90a1a8697",
      "96ce0742a2a247dd84d85ad7b5286f19",
      "b67a770e477e40b3a7ca8f4570cb2129",
      "79dfa298db314ce2874e86abd8e6b1ba",
      "38700d9515ca4ee694010fd7914e0d18",
      "7819396bd89b4917beac22678b04b9ec",
      "bdbd0b350dbd49e9b463993a3d5c0e92",
      "8f1faff5468a46d4a725d095ae31ea3c",
      "4a704f4b14614fe6934420a895d9d1a0",
      "e67dfbfbba4d4f4298b7ef302830ab40",
      "9b6572529f65495693d840718d37e744",
      "f06f07a6a1b94dfa9091651c9e95f6f4",
      "c3bea8260e5f493d8a470ff98f025324",
      "60f44f8bb72645eba40d9320d9d6e447",
      "47905056428d4404b73049b3cc437a5a",
      "5edec95909a6434ebf0bfd8a60f5887e",
      "c9900bd2f3374f858680f5a40efa70a0",
      "003f8dc6323b40d29b4f827e14108b20",
      "1ef7d525ad2b4a57ae1118a0c3908b1a",
      "7630787d9003423c81eac646fb88edc6",
      "f41ca30bce18404b953b97548251b556",
      "371f6292472d4befb3d8fcfcca290fed",
      "4334bb17edbd4b279287ea9723a62a3c",
      "b3114bb6194149989d1fa63011299251",
      "4827624c03d848bbb473fe94b2d21c22",
      "3047608c78ef465199d52959a425c5c0",
      "8fb84b1203cb43b5803c11b4a77c0d42",
      "426281caaa3f47e393ea8b001123cb22",
      "6381166be9444c0a9b98186e978e94cb",
      "fe28321b0bf04f58b0d63e7dc617e3ed",
      "77335dfe86c34eb08f9085b6b839b8c7",
      "49e7c650e0cc4b449ddd2d50f989d541",
      "c502fd2bf724410dbcf1528c79f220ce",
      "1b8d5199f7144981b5e9ae71f8ea8199",
      "2fa87811a24f4b6e9695d7b80817a422",
      "25133a67be974e6293bcdb3507529406",
      "fdbff4f0bd6b4989b72f8252b5faea16",
      "189edd39642b421f879956bea51d853e",
      "740ffbd464f041a283b9b2d9396b180c",
      "f5661357cbc144c5947529a979360114",
      "ec91a47eece543a495f36ed0e051d637",
      "443e64f8935544a0b4c159794fd8b272",
      "7dd0095387264941a52e8587ebd0fea1",
      "363406f847db494f972011724185b02a",
      "c21d3532550248b8a927756a510a2770",
      "82f03edadab54f949f92dd0c4a60bd55",
      "d2488adbea5344329da2b447382139f5",
      "fed393eac57747fabee1c2b743828ef8",
      "b1d82fdb948b4c5bbee4d327a0f41a21",
      "cccdb395613a4256950b7c3d740736fd",
      "24c7bdd72f3546c882a7a7c78de5925f",
      "db8a5ea365094bc4a87e77d059b4d0d0",
      "2f494500c50a42f0ba3589743048cdd8",
      "3ec4018cd5e54ba998a0f143f62407cc",
      "f3a87c6d2986429cb40979782b38e712",
      "4f7fb67e816b44598022407aacf71f19",
      "be9935d016a34ac5a272b51261053f13",
      "24540fc3ff1944edaa61e6037bec31c8",
      "713338a99be84b54877f8e35c953d8ba",
      "5586a425c639474ba5d6c0bd6d93328a",
      "088d87f186cc4a5d95745d8317cca20e",
      "acdecdef8bd14e44bcd36374b944b562",
      "1c7c3bfb5ae4472c9bb6e340c012d302",
      "41ae4c0601084403ba26a287f485ebeb",
      "916e61f972f6439b8135a70100753917",
      "36c3f462830247d7a219f1722cae8791",
      "69ae06a22fa9488598ed89641cc135b6",
      "c5ca864cc0144ddeb72dcbf1f8303609",
      "728f786930a14c7a91cb4ff1f97a24ee",
      "71704d8853ed40c4a55fa06669393ec9",
      "af5c196783e349888eaefc227beadbf0",
      "d3aee68f69ad4e5d81a087ec791cc9b1",
      "1ec887eb8dac43ba9922e1f9f2111231",
      "aa6b598305944d5ab2e2b4afaea8063c",
      "a132d68b4ae94f64b80893b9149f7fd8",
      "ec8f420a6f7d413bb528a1661aa3a0e8",
      "b70265a81e9a49109c18eaad44135562",
      "67a1b2e8e39b48849441368c33e16be4",
      "e2ec06c317034b5681d83347b530362f",
      "97bcd619eea74ed99650a1d8fed1f406",
      "14bc6db53fa449049a6a63b422ee54bc",
      "70f9cecf2dca4a3badc609b10ffcc8ec",
      "cc082399aef94823b67d6e9c33d468e5",
      "b4fb273306e941ebaa529e781361acfb"
     ]
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "8b36524b-d22e-43f2-a6e0-cc4209d76736"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
    "import torch\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\", # Llama 3.2 vision support\n",
    "    \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\", # Can fit in a 80GB card!\n",
    "    \"unsloth/Llama-3.2-90B-Vision-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/Pixtral-12B-2409-bnb-4bit\",              # Pixtral fits in 16GB!\n",
    "    \"unsloth/Pixtral-12B-Base-2409-bnb-4bit\",         # Pixtral base model\n",
    "\n",
    "    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",          # Qwen2 VL support\n",
    "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Qwen2-VL-72B-Instruct-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit\",      # Any Llava variant works!\n",
    "    \"unsloth/llava-1.5-7b-hf-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Pixtral-12B-2409\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters for parameter efficient finetuning - this allows us to only efficiently train 1% of all parameters.\n",
    "\n",
    "**[NEW]** We also support finetuning ONLY the vision part of the model, or ONLY the language part. Or you can select both! You can also select to finetune the attention or the MLP layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bZsfBuZDeCL"
   },
   "outputs": [],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    # We do NOT finetune vision & attention layers since Pixtral uses more memory!\n",
    "    finetune_vision_layers     = True, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True,  # False if not finetuning language layers\n",
    "    finetune_attention_modules = False, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True,  # False if not finetuning MLP layers\n",
    "\n",
    "    r = 8,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n",
    "We'll be using a sampled dataset of general question and answering pairs. These datasets should be mixed with other finetunes to not make the model forget general tasks.\n",
    "\n",
    "You can access the dataset [here](https://huggingface.co/datasets/unsloth/llava-instruct-mix-vsft-mini). The full dataset is [here](https://huggingface.co/datasets/HuggingFaceH4/llava-instruct-mix-vsft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "453a07e03ee94f528890205d14511da6",
      "309ebf7d588244a3ba28d29d56edbc2a",
      "dcc1ef7862e240eebefd5985202ef3b2",
      "0ef444f87c454640aa657c4c187e94f5",
      "d291b920db4b48fb9f3e89bc916db8c8",
      "3570f6aec06d461e9259a2bd60c6a16a",
      "3ed61e45df71452f844c1f39ea5c9dcf",
      "2b6b7fd9d5204198953a0f6fe8333d57",
      "e74c5834491b46d5b065665533671407",
      "fc9a5b89da594730a09a6bb4c3adb879",
      "22b0b4a4585148b2b6f75ecd86ebded3",
      "94a24760f2e3453aa615caf5300cd9da",
      "52e83aca1e544ffaabc57d149dd0415e",
      "b2e5c457d6a246cabcd71459cf2cee8d",
      "b8b672b219c347c4a636c1a43f73fda9",
      "76e1e2ae0a2944de8eff1c8eea325164",
      "6795172d2bb54298ae68cb481cf84822",
      "c09587db5ef3473490c1638c359ca945",
      "58e75f4e6c3e4ca9a6e6bc6e9865de67",
      "0fd6dae874a344678bac899cca709c3b",
      "da76163d3abd4ab9b4a7d02efdb15f00",
      "dc79ba710e9f4485a6f51d48963c6666",
      "9f45d79473ef446ca8f81c08ec82edda",
      "c381bddbbb6a4bbd99f90546dfb1867c",
      "9ca49f19650848dfbade44d036e166d2",
      "348f47ec75d44295b089a0071b747010",
      "d7601975774c43e4af927247019c2dab",
      "46513f9858a8403b93fc2fb1a0ea8779",
      "3d378819a2084a7797e8e8debf9bf815",
      "d2080299e24d40cbaecf75aead507415",
      "7d64c5f1dac64a49b794e723a5c77620",
      "08acfb1a242542d9990577d62118185f",
      "6cdfb3c8a1bc45b1ad34dd77feb4d4fe",
      "7856e0634b86431382280c591b6f740f",
      "cac2e90d5e3449978089a9fe4690cd93",
      "01838b1fb6da41e6bee2c632f9873b6e",
      "12b8a9e56ff646d4ba7032405183daf3",
      "2ef9f2c39bdf4893a4016e0880445e0f",
      "d358e59f602245fc96651c018347c448",
      "b7aeadfe764542e3ae4dd47e2664e410",
      "10523b38a16b4a48b095860653d34a6c",
      "ac9cb94447274626afc8580dd17260ad",
      "c6bc57fe79f045fabe94281cbe1bd09a",
      "05e888e211274b269794cde826c7d1f9",
      "6b2c1870e4ae44aba0326535f75c6858",
      "c3997e6823fb40349d9c92e32ce28045",
      "a4cf715dfb534feb814d426c2cac2b8e",
      "f57ddd4b011e428e82a86317d15779aa",
      "be6e313fb0b045adb8d8da6702081a0d",
      "dc07e208294f47d8b122afc8d415e3c8",
      "c2d88ba605ab4c2ab3f9686c5b65b8e8",
      "625723d424624ab2ac641b2c369da9e8",
      "35f6d9677b67401699e094040eaf8bd2",
      "ed9c8e6297654278bb360c13134920cb",
      "39d1ac1f430544c087b69e3bdb6ab5d6"
     ]
    },
    "id": "LjY75GoYUCB8",
    "outputId": "54b0ee23-5573-407a-d22f-cda8378461da"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"unsloth/llava-instruct-mix-vsft-mini\", split = \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9CBpiISFa6C"
   },
   "source": [
    "To format the dataset, all vision finetuning tasks should be formatted as follows:\n",
    "\n",
    "```python\n",
    "[\n",
    "{ \"role\": \"user\",\n",
    "  \"content\": [{\"type\": \"text\",  \"text\": Q}, {\"type\": \"image\", \"image\": image} ]\n",
    "},\n",
    "{ \"role\": \"assistant\",\n",
    "  \"content\": [{\"type\": \"text\",  \"text\": A} ]\n",
    "},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1W2Qhsz6rUT"
   },
   "source": [
    "Let's take an overview look at the dataset. We shall see what the 3rd image is, and what caption it had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfcSGwIb6p_R",
    "outputId": "9fa901ac-c7f5-4c6f-9ca0-fce9be962f8a"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "uOLWY2936t1n",
    "outputId": "f5cc8408-7f06-4dad-8a70-5feac66dcf90"
   },
   "outputs": [],
   "source": [
    "dataset[2][\"images\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTzhtzNRAEL1",
    "outputId": "556b7b48-250b-43ac-d5eb-aacfc45da6a6"
   },
   "outputs": [],
   "source": [
    "dataset[2][\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!\n",
    "\n",
    "We use our new `UnslothVisionDataCollator` which will help in our vision finetuning setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95_Nn-89DhsL",
    "outputId": "5582d21d-014f-4146-ca9d-7714f453eb7b"
   },
   "outputs": [],
   "source": [
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer, resize = 512), # Must use!\n",
    "    train_dataset = dataset,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size=2, # Reduce to 1 to make Pixtral fit!\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 30,\n",
    "        # num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        optim = \"paged_adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir=\"/workspace/outputs\",\n",
    "        report_to = \"none\",     # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        max_length = 2048,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ejIt2xSNKKp",
    "outputId": "21745cf1-b1cc-436a-f7f4-bd730d323f88"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Enhanced GPU check for NVIDIA Brev\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU Information\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run nvidia-smi\n",
    "subprocess.run(['nvidia-smi'], check=False)\n",
    "\n",
    "# PyTorch CUDA info\n",
    "import torch\n",
    "print(f\"\\nPyTorch CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"    Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "23f5f103-5258-4978-f86e-b38e6e62baff"
   },
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCqnaKmlO1U9",
    "outputId": "dd333e5f-10a7-40ab-ff08-ae1a6dcc51bd"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Enhanced GPU check for NVIDIA Brev\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU Information\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run nvidia-smi\n",
    "subprocess.run(['nvidia-smi'], check=False)\n",
    "\n",
    "# PyTorch CUDA info\n",
    "import torch\n",
    "print(f\"\\nPyTorch CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"    Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekOmTR1hSNcr"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model! You can change the instruction and input - leave the output blank!\n",
    "\n",
    "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR3gIAX-SM2q",
    "outputId": "f249dae0-076a-431a-85ea-df7e6c7e2fac"
   },
   "outputs": [],
   "source": [
    "# Fix torch compilation cache permissions\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Test if /ephemeral is writable (not just readable)\n",
    "use_ephemeral = False\n",
    "if os.path.exists(\"/ephemeral\"):\n",
    "    try:\n",
    "        test_file = \"/ephemeral/.write_test\"\n",
    "        with open(test_file, \"w\") as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        use_ephemeral = True\n",
    "    except (PermissionError, OSError):\n",
    "        pass\n",
    "\n",
    "if use_ephemeral:\n",
    "    cache_dir = \"/ephemeral/torch_cache\"\n",
    "    triton_cache = \"/ephemeral/triton_cache\"\n",
    "    tmpdir = \"/ephemeral/tmp\"\n",
    "else:\n",
    "    cache_dir = os.path.expanduser(\"~/.cache/torch/inductor\")\n",
    "    triton_cache = os.path.expanduser(\"~/.cache/triton\")\n",
    "    tmpdir = os.path.expanduser(\"~/.cache/tmp\")\n",
    "\n",
    "# Create directories with full write permissions\n",
    "for d in [cache_dir, triton_cache, tmpdir]:\n",
    "    os.makedirs(d, mode=0o777, exist_ok=True)\n",
    "\n",
    "# Set ALL PyTorch/Triton cache and temp directories\n",
    "os.environ[\"TORCHINDUCTOR_CACHE_DIR\"] = cache_dir\n",
    "os.environ[\"TORCH_COMPILE_DIR\"] = cache_dir\n",
    "os.environ[\"TRITON_CACHE_DIR\"] = triton_cache\n",
    "os.environ[\"TMPDIR\"] = tmpdir  # Override system /tmp\n",
    "os.environ[\"TEMP\"] = tmpdir\n",
    "os.environ[\"TMP\"] = tmpdir\n",
    "\n",
    "# Clean up any old compiled caches\n",
    "old_cache = os.path.join(os.getcwd(), \"unsloth_compiled_cache\")\n",
    "if os.path.exists(old_cache):\n",
    "    shutil.rmtree(old_cache, ignore_errors=True)\n",
    "\n",
    "print(f\"‚úÖ Torch cache: {cache_dir}\")\n",
    "print(f\"‚úÖ Temp dir: {tmpdir}\")\n",
    "\n",
    "FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "image = dataset[2][\"images\"][0]\n",
    "instruction = \"Is there something interesting about this image?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 64,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving, loading finetuned models\n",
    "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
    "\n",
    "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upcOlWe7A1vc",
    "outputId": "3095feda-bd25-45ca-8576-efae8c014e8b"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKX_XKs_BNZR",
    "outputId": "ca395c7d-69e5-40d1-854c-fa3e9a42b121"
   },
   "outputs": [],
   "source": [
    "# Fix torch compilation cache permissions\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Test if /ephemeral is writable (not just readable)\n",
    "use_ephemeral = False\n",
    "if os.path.exists(\"/ephemeral\"):\n",
    "    try:\n",
    "        test_file = \"/ephemeral/.write_test\"\n",
    "        with open(test_file, \"w\") as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        use_ephemeral = True\n",
    "    except (PermissionError, OSError):\n",
    "        pass\n",
    "\n",
    "if use_ephemeral:\n",
    "    cache_dir = \"/ephemeral/torch_cache\"\n",
    "    triton_cache = \"/ephemeral/triton_cache\"\n",
    "    tmpdir = \"/ephemeral/tmp\"\n",
    "else:\n",
    "    cache_dir = os.path.expanduser(\"~/.cache/torch/inductor\")\n",
    "    triton_cache = os.path.expanduser(\"~/.cache/triton\")\n",
    "    tmpdir = os.path.expanduser(\"~/.cache/tmp\")\n",
    "\n",
    "# Create directories with full write permissions\n",
    "for d in [cache_dir, triton_cache, tmpdir]:\n",
    "    os.makedirs(d, mode=0o777, exist_ok=True)\n",
    "\n",
    "# Set ALL PyTorch/Triton cache and temp directories\n",
    "os.environ[\"TORCHINDUCTOR_CACHE_DIR\"] = cache_dir\n",
    "os.environ[\"TORCH_COMPILE_DIR\"] = cache_dir\n",
    "os.environ[\"TRITON_CACHE_DIR\"] = triton_cache\n",
    "os.environ[\"TMPDIR\"] = tmpdir  # Override system /tmp\n",
    "os.environ[\"TEMP\"] = tmpdir\n",
    "os.environ[\"TMP\"] = tmpdir\n",
    "\n",
    "# Clean up any old compiled caches\n",
    "old_cache = os.path.join(os.getcwd(), \"unsloth_compiled_cache\")\n",
    "if os.path.exists(old_cache):\n",
    "    shutil.rmtree(old_cache, ignore_errors=True)\n",
    "\n",
    "print(f\"‚úÖ Torch cache: {cache_dir}\")\n",
    "print(f\"‚úÖ Temp dir: {tmpdir}\")\n",
    "\n",
    "if False:\n",
    "    from unsloth import FastVisionModel\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = True, # Set to False for 16bit LoRA\n",
    "    )\n",
    "    FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "image = dataset[2][\"images\"][0]\n",
    "instruction = \"What colors are in the image?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 64,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f422JgM9sdVT"
   },
   "source": [
    "### Saving to float16 for VLLM\n",
    "\n",
    "We also support saving to `float16` directly. Select `merged_16bit` for float16. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHjt_SMYsd3P"
   },
   "outputs": [],
   "source": [
    "# Select ONLY 1 to save! (Both not needed!)\n",
    "\n",
    "# Save locally to 16bit\n",
    "if False: model.save_pretrained_merged(\"unsloth_finetune\", tokenizer,)\n",
    "\n",
    "# To export and save to your Hugging Face account\n",
    "if False: model.push_to_hub_merged(\"YOUR_USERNAME/unsloth_finetune\", tokenizer, token = \"PUT_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "**Additional Resources:**\n",
    "\n",
    "- üìö [Unsloth Documentation](https://docs.unsloth.ai) - Complete guides and examples\n",
    "- üí¨ [Unsloth Discord](https://discord.gg/unsloth) - Community support\n",
    "- üìñ [More Notebooks](https://github.com/unslothai/notebooks) - Full collection on GitHub\n",
    "- üöÄ [Brev Documentation](https://docs.nvidia.com/brev) - Deploy and scale on NVIDIA GPUs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
