{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47058f34",
   "metadata": {},
   "source": [
    "# ü§ô Kaggle Gemma3N (2B) Inference on NVIDIA Brev\n",
    "\n",
    "<div style=\"background: linear-gradient(90deg, #00ff87 0%, #60efff 100%); padding: 1px; border-radius: 8px; margin: 20px 0;\">\n",
    "    <div style=\"background: #0a0a0a; padding: 20px; border-radius: 7px;\">\n",
    "        <p style=\"color: #60efff; margin: 0;\"><strong>‚ö° Powered by Brev</strong> | Converted from <a href=\"https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(2B)-Inference.ipynb\" style=\"color: #00ff87;\">Unsloth Notebook</a></p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "## üìã Configuration\n",
    "\n",
    "<table style=\"width: auto; margin-left: 0; border-collapse: collapse; border: 1px solid rgba(128, 128, 128, 0.5);\">\n",
    "    <tr style=\"border-bottom: 2px solid rgba(128, 128, 128, 0.5); background-color: rgba(128, 128, 128, 0.1);\">\n",
    "        <th style=\"text-align: left; padding: 8px 12px; border-right: 1px solid rgba(128, 128, 128, 0.5); font-weight: bold;\">Parameter</th>\n",
    "        <th style=\"text-align: left; padding: 8px 12px; font-weight: bold;\">Value</th>\n",
    "    </tr>\n",
    "    <tr style=\"border-bottom: 1px solid rgba(128, 128, 128, 0.3);\">\n",
    "        <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid rgba(128, 128, 128, 0.5);\"><strong>Model</strong></td>\n",
    "        <td style=\"text-align: left; padding: 8px 12px;\">Kaggle Gemma3N (2B) Inference</td>\n",
    "    </tr>\n",
    "    <tr style=\"border-bottom: 1px solid rgba(128, 128, 128, 0.3);\">\n",
    "        <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid rgba(128, 128, 128, 0.5);\"><strong>Recommended GPU</strong></td>\n",
    "        <td style=\"text-align: left; padding: 8px 12px;\">L4</td>\n",
    "    </tr>\n",
    "    <tr style=\"border-bottom: 1px solid rgba(128, 128, 128, 0.3);\">\n",
    "        <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid rgba(128, 128, 128, 0.5);\"><strong>Min VRAM</strong></td>\n",
    "        <td style=\"text-align: left; padding: 8px 12px;\">16 GB</td>\n",
    "    </tr>\n",
    "    <tr style=\"border-bottom: 1px solid rgba(128, 128, 128, 0.3);\">\n",
    "        <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid rgba(128, 128, 128, 0.5);\"><strong>Batch Size</strong></td>\n",
    "        <td style=\"text-align: left; padding: 8px 12px;\">2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; padding: 8px 12px; border-right: 1px solid rgba(128, 128, 128, 0.5);\"><strong>Categories</strong></td>\n",
    "        <td style=\"text-align: left; padding: 8px 12px;\">fine-tuning</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "## üîß Key Adaptations for Brev\n",
    "\n",
    "- ‚úÖ Replaced Colab-specific installation with conda-based Unsloth\n",
    "- ‚úÖ Converted magic commands to subprocess calls\n",
    "- ‚úÖ Removed Google Drive dependencies\n",
    "- ‚úÖ Updated paths from `/workspace/` to `/workspace/`\n",
    "- ‚úÖ Added `device_map=\"auto\"` for multi-GPU support\n",
    "- ‚úÖ Optimized batch sizes for NVIDIA GPUs\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [Unsloth Documentation](https://docs.unsloth.ai/)\n",
    "- [Brev Documentation](https://docs.nvidia.com/brev)\n",
    "- [Original Notebook](https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Gemma3N_(2B)-Inference.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
    "</div>\n",
    "\n",
    "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
    "\n",
    "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://github.com/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
    "\n",
    "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
    "\n",
    "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
    "\n",
    "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQO6mdlThz35"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", 'pip3-autoremove'])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", 'torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu128'])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", 'unsloth'])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers==4.56.2'])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", '--no-deps trl==0.22.2'])\n",
    "import torch; torch._dynamo.config.recompile_limit = 64;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-FHlY-fhz36"
   },
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtV7V3HkfLZN"
   },
   "source": [
    "### Launch sglang inference for unsloth/gemma-3n-E2B-it (https://huggingface.co/unsloth/gemma-3n-E2B-it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1hV9-YHp0FQ",
    "outputId": "c31f4794-d31e-447d-addb-8ce65bd2f566"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Load and run the model using sglang\n",
    "subprocess.run(['nohup python -m sglang.launch_server --model-path unsloth/gemma-3n-E2B-it --attention-backend fa3 --port 8000 > sglang.log &'], check=True, shell=True)\n",
    "\n",
    "# tail vllm logs. Check server has been started correctly\n",
    "subprocess.run(['while ! grep -q \"The server is fired up and ready to roll\" sglang.log; do tail -n 1 sglang.log; sleep 5; done'], check=True, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDGMqFWCiwMT"
   },
   "source": [
    "### Image helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RXVBeib0kon"
   },
   "outputs": [],
   "source": [
    "from PIL.ImageFile import ImageFile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "def process_image(image: ImageFile) -> str:\n",
    "    \"\"\"Process image for sglang gemma3n and return base64 string.\"\"\"\n",
    "    assert isinstance(image, ImageFile), \"please pass an image object\"\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = image.resize((384, 384))\n",
    "\n",
    "    # Convert to numpy array and transpose\n",
    "    image_array = np.array(resized_image)\n",
    "    array_reordered = np.transpose(image_array, (1, 0, 2))\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    processed_image = Image.fromarray(array_reordered)\n",
    "\n",
    "    # Convert to base64 string\n",
    "    image_bytes = io.BytesIO()\n",
    "    processed_image.save(image_bytes, format=image.format)\n",
    "    base64_image = base64.b64encode(image_bytes.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "    # Return data URL string\n",
    "    format_name = image.format.lower() if image.format else 'png'\n",
    "    return f\"data:image/{format_name};base64,{base64_image}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go18XrL7fd2e"
   },
   "source": [
    "## Gemma3n Inference using sglang (source model: https://huggingface.co/unsloth/gemma-3n-E2B-it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78Vmthuthz37"
   },
   "source": [
    "## Inference 1\n",
    "Image source file \"https://raw.githubusercontent.com/sgl-project/sglang/refs/heads/main/test/lang/example_image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQRc2IBUhz37"
   },
   "source": [
    "load image from url source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "_9FCs0cq6Lwc",
    "outputId": "d5886cc4-3e44-4458-a0d5-ed4f18d56f01"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "image = load_image_from_url(\"https://raw.githubusercontent.com/sgl-project/sglang/refs/heads/main/test/lang/example_image.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wHYNCu5hz37"
   },
   "source": [
    "Let's run the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQ7xEqVahz37",
    "outputId": "0307322a-77cb-484d-d3f4-0d4e90d96e82"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from sglang.utils import wait_for_server, print_highlight, terminate_process\n",
    "\n",
    "processed_image = process_image(image)\n",
    "url = f\"http://localhost:8000/v1/chat/completions\"\n",
    "\n",
    "processed_image = process_image(image)\n",
    "data = {\n",
    "    \"model\": \"unsloth/gemma-3n-E2B-it\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What‚Äôs in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": processed_image\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print_highlight(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPhQfbqehz37"
   },
   "source": [
    "## Inference 2\n",
    "Image source file \"https://i.ibb.co/1tw5whfz/ocr.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc5hlsXvhz37"
   },
   "source": [
    "load image from url source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "69oNhkD9hz37",
    "outputId": "9c3562cb-48b6-4fb0-a657-8607181c18af"
   },
   "outputs": [],
   "source": [
    "image = load_image_from_url(\"https://i.ibb.co/1tw5whfz/ocr.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzCOblKLhz37"
   },
   "source": [
    "Let's run the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCN1P2gJhz37",
    "outputId": "a95761da-3e82-4bf9-8d1e-f75c7d5cb385"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"http://localhost:8000/v1/chat/completions\"\n",
    "processed_image = process_image(image)\n",
    "data = {\n",
    "    \"model\": \"unsloth/gemma-3n-E2B-it\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Read the text in the image\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": processed_image\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print_highlight(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "**Additional Resources:**\n",
    "\n",
    "- üìö [Unsloth Documentation](https://docs.unsloth.ai) - Complete guides and examples\n",
    "- üí¨ [Unsloth Discord](https://discord.gg/unsloth) - Community support\n",
    "- üìñ [More Notebooks](https://github.com/unslothai/notebooks) - Full collection on GitHub\n",
    "- üöÄ [Brev Documentation](https://docs.nvidia.com/brev) - Deploy and scale on NVIDIA GPUs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
